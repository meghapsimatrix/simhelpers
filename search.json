[{"path":[]},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"absolute-criteria","dir":"Articles","previous_headings":"Performance Criteria and MCSE","what":"Absolute Criteria","title":"Simulation Performance Criteria and MCSE","text":"Bias characterizes whether estimator tends lie true parameter, average. Variance characterizes precision estimator, average squared deviation estimator average. Note variance inverse precision. Therefore, higher variance, lower precision. Mean squared error (MSE) root mean squared error (RMSE) characterize accuracy estimates. MSE RMSE measure far , average, estimator true parameter. Absolute criteria scale estimate. MSE squared deviation scale RMSE scale estimates. Let \\(T\\) denote estimator parameter \\(\\theta\\). running simulation study, obtain \\(K\\) estimates \\(T_1,...,T_K\\) (realizations estimator) data generating condition. can calculate following sample statistics estimates: Sample mean: \\(\\bar{T} = \\frac{1}{K}\\sum_{k=1}^K T_k\\) Sample variance: \\(S_T^2 = \\frac{1}{K - 1}\\sum_{k=1}^K \\left(T_k - \\bar{T}\\right)^2\\) Sample skewness (standardized): \\(g_T = \\frac{1}{K S_T^3}\\sum_{k=1}^K \\left(T_k - \\bar{T}\\right)^3\\) Sample kurtosis (standardized): \\(k_T = \\frac{1}{K S_T^4} \\sum_{k=1}^K \\left(T_k - \\bar{T}\\right)^4\\) Table 1 shows performance criteria, interpretation, formal definition, criterion estimated simulation study, formula MCSE estimated performance measure. Table 1. Absolute Performance Criteria equation MCSE RMSE derived using jack-knife technique, involves excluding replicate \\(j\\) calculating RMSE (Efron & Stein, 1981). formula RMSE : \\[\\sqrt{\\frac{1}{K}\\sum_{k=1}^{K}\\left(T_k - \\theta\\right)^2}\\] approximately equivalent : \\[RMSE = \\sqrt{(\\bar{T} - \\theta)^2 + S^2_T}\\] jack-knife RMSE calculated : \\[RMSE_{(j)}  = \\sqrt{(\\bar{T}_{(j)} - \\theta)^2 + S^2_{T(j)}}\\] \\(\\bar{T}_{(j)}\\) \\(S^2_{T(j)}\\) indicate mean variance estimates leaving replicate \\(j\\). Instead calculating jack-knife estimate, use algebraic tricks calculate \\(\\bar{T}_{(j)}\\) \\(S^2_{T(j)}\\) follows: \\[\\bar{T}_{(j)} = \\frac{1}{K-1} \\left(K \\bar{T} - T_j\\right)\\] \\[S_{T(j)}^2 = \\frac{1}{K - 2} \\left[(K - 1) S_T^2 - \\frac{K}{K - 1}\\left(T_j - \\bar{T}\\right)^2\\right]\\] , jack-knife MCSE RMSE calculated : \\[MCSE_{RMSE(JK)}  = \\sqrt{\\frac{K -1}{K}\\sum_{j=1}^K  \\left(RMSE_{(j)} - RMSE\\right)^2}\\]","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"example","dir":"Articles","previous_headings":"Performance Criteria and MCSE > Absolute Criteria","what":"Example","title":"Simulation Performance Criteria and MCSE","text":"use welch_res dataset included package. contains results example simulation study comparing heteroskedasticity-robust Welch t-test usual two-sample t-test assuming equal variances. code used generate data derive results can found . varied sample sizes per group. set sample size Group 1 50 varied sample size Group 2 50 70. varied mean difference parameter generating data two groups. set values 0, 0.5, 1 2. generated data slightly unequal variances. simulated dataset, ran usual t-test, assumes homogeneity variance, also ran Welch t-test, assume homogeneity variance. extracted estimates (mean differences), variances estimates, p-values, lower upper bounds confidence intervals. , calculate absolute performance criteria estimates mean differences. present results sample sizes, mean difference, t-test method. calc_absolute() function designed work tidyeval workflow (Wickham et al., 2019). first argument, res_dat, requires data frame tibble containing results simulation study. second argument, estimates, requires name column containing estimates like mean difference regression coefficients. third argument, true_param, requires name column containing true parameters. fourth argument, perfm_criteria, lets user specify criteria evaluate. criteria can specified using character character vector. user wants bias, can specify perfm_criteria = \"bias\". user wants bias root mean squared error, can specify perfm_criteria = c(\"bias\", \"rmse\"). default, function returns bias, variance, mean squared error (mse), root mean squared error (rmse), perfm_criteria = c(\"bias\", \"variance\", \"mse\", \"rmse\"). example , ask available criteria. calculate absolute performance measures conventional t-test results mean difference identical Welch t-test. use dplyr syntax group sample sizes mean difference used generate data. provide examples using () group_modify() run calc_absolute() results combination conditions. Results rounded five decimal places. convergence issues estimation, please make sure write estimation function output NA values point estimates, variance estimates, p-values, confidence interval estimates. functions simhelpers package calculate performance criteria MCSE deleting missing estimates output number iterations, K, exclude iterations NA values estimates. Note K may differ condition.","code":"library(simhelpers) library(dplyr) library(tibble) library(knitr) library(dplyr) library(kableExtra)  welch_res %>%   glimpse() #> Rows: 16,000 #> Columns: 11 #> $ n1          <dbl> 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50… #> $ n2          <dbl> 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50… #> $ mean_diff   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… #> $ iterations  <dbl> 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000… #> $ seed        <dbl> 204809087, 204809087, 204809087, 204809087, 204809087, 204… #> $ method      <chr> \"t-test\", \"Welch t-test\", \"t-test\", \"Welch t-test\", \"t-tes… #> $ est         <dbl> 0.025836000, 0.025836000, 0.005158587, 0.005158587, -0.079… #> $ var         <dbl> 0.09543914, 0.09543914, 0.08481717, 0.08481717, 0.08179330… #> $ p_val       <dbl> 0.9335212, 0.9335804, 0.9859039, 0.9859109, 0.7807543, 0.7… #> $ lower_bound <dbl> -0.5872300, -0.5899041, -0.5727856, -0.5741984, -0.6473703… #> $ upper_bound <dbl> 0.6389020, 0.6415761, 0.5831027, 0.5845155, 0.4877263, 0.4… # using do() welch_res %>%   filter(method == \"t-test\") %>% # filter just conventional t-test res   group_by(n1, n2, mean_diff) %>% # grouping    do(calc_absolute(., estimates = est, true_param = mean_diff)) %>% # run the function   kable(digits = 5) # create a kable table # using group_modify() welch_res %>%   filter(method == \"t-test\") %>% # filter just conventional t-test res   mutate(params = mean_diff) %>% # group_modify cannot take in a group column as an argument   group_by(n1, n2, mean_diff) %>% # grouping    group_modify(~ calc_absolute(.x, estimates = est, true_param = params)) %>%   kable(digits = 5)"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"relative-criteria","dir":"Articles","previous_headings":"Performance Criteria and MCSE","what":"Relative Criteria","title":"Simulation Performance Criteria and MCSE","text":"Relative criteria can useful describing estimator’s performance, especially performance varies proportion true value target parameter. can used \\(|\\theta| > 0\\) divide \\(0\\) (Morris et al., 2019). derive MCSE relative RMSE, used jack-knife technique. formula calculate relative RMSE : \\[rRMSE = \\sqrt{\\frac{(\\bar{T} - \\theta)^2 + S_T^2}{\\theta^2}}\\] jack-knife RMSE calculated : \\[rRMSE_{(j)}  = \\sqrt{\\frac{(\\bar{T}_{(j)} - \\theta)^2 + S_{T(j)}^2}{\\theta^2}}\\] \\(\\bar{T}_{(j)}\\) \\(S^2_{T(j)}\\) calculated specified described algebra trick estimate values. MCSE calculated specified table . Table 2 shows relative performance criteria, interpretation, formal definition, criterion estimated simulation study, MCSE formula. Table 2. Relative Performance Criteria","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"example-1","dir":"Articles","previous_headings":"Performance Criteria and MCSE > Relative Criteria","what":"Example","title":"Simulation Performance Criteria and MCSE","text":", calculate relative criteria mean difference estimates. Note mean difference 0, relative measures calculated function returns NA values. syntax calc_relative() similar one used earlier calc_absolute(). perfm_criteria argument allows user specify criteria evaluate: perfm_criteria = c(\"relative bias\", \"relative mse\", \"relative rmse\").","code":"# using group_modify() welch_res %>%   filter(method == \"t-test\") %>%   mutate(params = mean_diff) %>%   group_by(n1, n2, mean_diff) %>%   group_modify(~ calc_relative(.x, estimates = est, true_param = params)) %>%   kable(digits = 5)"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"relative-criteria-for-variance-estimators","dir":"Articles","previous_headings":"Performance Criteria and MCSE","what":"Relative Criteria for Variance Estimators","title":"Simulation Performance Criteria and MCSE","text":"Variance estimators always positive, relative criteria often used characterize performance. variance estimators, \\(V\\) denoting sampling variance point estimator \\(T\\). assess relative criteria \\(V\\), need divide true value sampling variance \\(T\\), \\(\\lambda = \\text{Var}(T)\\), may able calculate directly. scenario, can use sample variance \\(T\\) across replications, \\(S_T^2\\), estimate true sampling variance. relative bias estimated \\(rB = \\bar{V} / S_T^2\\), average variance estimates divided sample variance point estimates. estimate MCSE relative bias variance estimator, need account uncertainty estimation true sampling variance. One way use jack-knife technique described , entails excluding replicate \\(j\\) calculating relative bias \\(\\bar{V}_{(j)}/ S_{T(j)}^2\\). Monte Carlo standard error can calculated : \\[ MCSE\\left(rB\\right) = \\sqrt{\\frac{K - 1}{K} \\sum_{j=1}^K \\left(rB_{(j)} - rB\\right)^2} \\] can written : \\[ MCSE\\left(rB\\right) = \\sqrt{\\frac{K - 1}{K} \\sum_{j=1}^K \\left(\\frac{\\bar{V}_{(j)}}{S_{T(j)}^2} - \\frac{\\bar{V}}{S_T^2}\\right)^2} \\] reformulate MCSE using algebra tricks similar reformulated RMSE MCSE formulas . \\[ \\begin{aligned} \\bar{V}_{(j)} &= \\frac{1}{K - 1}\\left(K \\bar{V} - V_j\\right) \\\\ S_{T(j)}^2 &= \\frac{1}{K - 2} \\left[(K - 1) S_T^2 - \\frac{K}{K - 1}\\left(T_j - \\bar{T}\\right)^2\\right] \\end{aligned} \\] Similarly, can estimate MCSE relative MSE RMSE using jack-knife technique. estimate MSE need estimate \\(S_{V(j)}^2\\), represents sample variance variance estimates leaving replicate \\(j\\) . calculate \\(S_{V(j)}^2\\) \\[S_{V(j)}^2 = \\frac{1}{K - 2} \\left[(K - 1) S_V^2 - \\frac{K}{K - 1}\\left(V_j - \\bar{V}\\right)^2\\right].\\] can estimate jack-knife relative MSE RMSE following logic described calculate MCSE. Table 3 lists relative performance measures variance estimators. Table 3. Relative Performance Criteria Variance Estimators function calc_relative_var() calculates relative performance criteria estimates corresponding jack-knife MCSEs variance estimator. function requires res_dat, data frame tibble containing simulation results, estimates, name column containing point estimates, var_estimates, name column containing variance estimates, perfm_criteria, criteria evaluated: perfm_criteria = c(\"relative bias\", \"relative mse\", \"relative rmse\"). demonstrate use calc_relative_var() function. variance estimates expected different derived conventional t-test opposed derived Welch t-test. group sample sizes, mean difference, t-test method. Note difference conventional t-test Welch t-test results, especially group sample sizes unequal. convergence issues estimation, please make sure estimation function returns NA values variance estimate point estimate. calc_relative_var() function omit pair point estimate variance estimate either value NA calculating performance measure MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"example-2","dir":"Articles","previous_headings":"Performance Criteria and MCSE > Relative Criteria for Variance Estimators","what":"Example","title":"Simulation Performance Criteria and MCSE","text":"","code":"welch_res %>%   group_by(n1, n2, mean_diff, method) %>%   group_modify(~ calc_relative_var(.x, estimates = est, var_estimates = var)) %>%   kable(digits = 5)"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"hypothesis-testing-and-confidence-intervals","dir":"Articles","previous_headings":"Performance Criteria and MCSE","what":"Hypothesis Testing and Confidence Intervals","title":"Simulation Performance Criteria and MCSE","text":"hypothesis tests, often interested whether Type 1 error rate adequately controlled whether test enough power detect effect size substantive interest. rejection rate hypothesis test captures proportion times p-value specified \\(\\alpha\\) level—, proportion times reject null hypothesis. specified effect size 0, can examine Type 1 error rates magnitude effect greater 0, can examine power. also interested confidence interval coverage, proportion intervals contain true parameter, interval width, indicator precision interval estimator. Table 4 presents performance criteria used evaluate hypothesis tests. table, let \\(P_k\\) denote p-value simulation replication \\(k\\), \\(k = 1,...,K\\). Suppose confidence intervals target parameter \\(\\theta\\) coverage level \\(\\beta\\). Let \\(A_k\\) \\(B_k\\) denote lower upper end-points confidence interval simulation replication \\(k\\), let \\(W_k = B_k − A_k\\), \\(k = 1,...,K\\). Table 4. Hypothesis Testing Confidence Intervals Performance Criteria","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"example-3","dir":"Articles","previous_headings":"Performance Criteria and MCSE > Hypothesis Testing and Confidence Intervals","what":"Example","title":"Simulation Performance Criteria and MCSE","text":"calculate rejection rates hypothesis tests conducted using conventional two-sample t-test Welch t-test. null hypothesis two groups means. calc_rejection() function requires data frame tibble containing simulation results first argument. second argument, p_values, requires name column containing p-values. third argument, alpha, lets user specify value \\(\\alpha\\). default value set conventional 0.05. calculate confidence interval coverage rates widths estimates mean difference. calc_coverage() function requires data frame tibble containing simulation results first argument. second third arguments, lower_bound upper_bound, take name columns contain lower upper bound estimates confidence intervals. true_param argument requires name column containing true parameters. Like calc_absolute(), calc_relative() calc_relative_var(), calc_coverage() also argument, perfm_criteria, user can specify criteria evaluate: perfm_criteria = c(\"coverage\", \"width\").","code":"# using group_modify() welch_res %>%   group_by(n1, n2, mean_diff, method) %>%   group_modify(~ calc_rejection(.x, p_values = p_val)) %>%   kable(digits = 5) # using group_modify() welch_res %>%   mutate(params = mean_diff) %>%   group_by(n1, n2, mean_diff, method) %>%   group_modify(~ calc_coverage(.x, lower_bound = lower_bound, upper_bound = upper_bound, true_param = params)) %>%   kable(digits = 5)"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"how-to-evaluate-mcse","dir":"Articles","previous_headings":"","what":"How to Evaluate MCSE","title":"Simulation Performance Criteria and MCSE","text":"Generally, associated MCSE small compared performance measure. example Frane (2015) write MCSE results part simulation study results. Frane (2015) compared various methods control Type 1 error rates conducting analysis multiple outcome variables. describing simulation results, wrote: Bonferroni MP strictly controlled PFER; observed maximum PFER 0.050 Bonferroni, 0.051 Sidák, 0.061 Holm, 0.100 Hochberg, 0.050 MP (estimated SE ≤ 0.0002 estimates). PFER refers per family error rate, expected number Type 1 errors \\(m\\) comparisons. MP refers multivariate analysis variance (MANOVA) protected tests. SE refers MCSE. number replications 1,000,000 Frane (2015). note number quite high generally 1,000 10,000 replications enough. resulting MCSEs Frane (2015), therefore, exceedingly small compared values PFER. information performance criteria MCSE, recommend Morris et al. (2019).","code":""},{"path":[]},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"initial-experimental-design","dir":"Articles","previous_headings":"","what":"Initial Experimental Design","title":"Simulation Workflow","text":"begin working simulation study, decide model design parameters want vary. Parameters can include sample size, proportion missing data etc.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"data-generating-model","dir":"Articles","previous_headings":"","what":"Data Generating Model","title":"Simulation Workflow","text":"data-generating function takes model parameters. example, can generate data varying sample size level heteroskedasticity amount missingness. skeleton data-generating function. arguments data-generating parameters want vary. example generate random normal data two groups, second group standard deviation twice large first group. function takes three arguments: n1, indicating sample size Group 1, n2 indicating sample size Group 2, mean_diff, indicating mean difference. creating data-generating function, check whether works. , generate example dataset 10,000 people group mean_diff set 1. , create summary table. mean outcome Group 1 close 1 mean Group 2 close 0. standard deviation outcome Group 1 close 1 standard deviation Group 2 close 2. table matches specified data-generating model. create density plot values generated groups. distributions seem normal. peaks seem difference 1. , variances outcome scores different group specified.","code":"generate_dat <- function(model_params) {    return(dat) } generate_dat <- function(n1, n2, mean_diff){    dat <- tibble(     y = c(rnorm(n = n1, mean_diff, 1), # mean diff as mean, sd 1           rnorm(n = n2, 0, 2)), # mean 0, sd 2     group = c(rep(\"Group 1\", n1), rep(\"Group 2\", n2))   )    return(dat)  } set.seed(2020143) example_dat <- generate_dat(n1 = 10000, n2= 10000, mean_diff = 1)   example_dat %>%   head() #> # A tibble: 6 × 2 #>        y group   #>    <dbl> <chr>   #> 1  0.491 Group 1 #> 2 -0.534 Group 1 #> 3  1.02  Group 1 #> 4  0.754 Group 1 #> 5  0.762 Group 1 #> 6  0.979 Group 1 example_dat %>%   group_by(group) %>%   summarize(n = n(),             M = mean(y),             SD = sd(y)) %>%   kable(digits = 3) ggplot(example_dat, aes(x = y, fill = group)) +    geom_density(alpha = .5) +    labs(x = \"Outcome Scores\", y = \"Density\", fill = \"Group\") +    theme_bw() +   theme(legend.position = c(0.9, 0.8))"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"estimation-methods","dir":"Articles","previous_headings":"","what":"Estimation Methods","title":"Simulation Workflow","text":"step, run statistical methods calculate test statistics, regression coefficients, p-values, confidence intervals. function takes data design parameters, options estimation carried (e.g., use HC0 standard errors HC2 standard errors). example function runs t-tests simulated dataset. function runs conventional t-test, assumes homogeneity variance, Welch t-test, assume population variances outcome two groups equal. function returns tibble containing names two methods, mean difference estimates, p-values, upper lower bounds confidence intervals. use t.test() function extract everything need. function implements calculations directly (using sample statistics) mostly just fun. reason t.test() function lot extra stuff handle contingencies come real data (like missing observations), unnecessary running calculations simulated data. , good check function runs . run estimate() function example dataset: can compare results built-t.test() function: values match.","code":"estimate <- function(dat, design_params) {    return(results) } # t and p value calc_t <- function(est, vd, df, method){    se <- sqrt(vd)  # standard error    t <- est / se # t-test    p_val <-  2 * pt(-abs(t), df = df) # p value   ci <- est + c(-1, 1) * qt(.975, df = df) * se # confidence interval      res <- tibble(method = method, est = est, p_val = p_val,                  lower_bound = ci[1], upper_bound = ci[2])    return(res) }   estimate <- function(dat, n1, n2){    # calculate summary stats   means <- tapply(dat$y, dat$group, mean)   vars <- tapply(dat$y, dat$group, var)    # calculate summary stats   est <- means[1] - means[2] # mean diff   var_1 <- vars[1] # var for group 1   var_2 <- vars[2] # var for group 2    # conventional t-test   dft <- n1 + n2 - 2  # degrees of freedom   sp_sq <- ((n1 - 1) * var_1 + (n2 - 1) * var_2) / dft  # pooled var   vdt <- sp_sq * (1 / n1 + 1 / n2) # variance of estimate    # welch t-test   dfw <- (var_1 / n1 + var_2 / n2)^2 / (((1 / (n1 - 1)) * (var_1 / n1)^2) + ((1 / (n2 - 1)) * (var_2 / n2)^2))  # degrees of freedom    vdw <- var_1 / n1 + var_2 / n2 # variance of estimate    results <- bind_rows(calc_t(est = est, vd = vdt, df = dft, method = \"t-test\"),                    calc_t(est = est, vd = vdw, df = dfw, method = \"Welch t-test\"))     return(results)  } est_res <-    estimate(example_dat, n1 = 10000, n2 = 10000) %>%   mutate_if(is.numeric, round, 5)  est_res #> # A tibble: 2 × 5 #>   method         est p_val lower_bound upper_bound #>   <chr>        <dbl> <dbl>       <dbl>       <dbl> #> 1 t-test        1.01     0       0.967        1.06 #> 2 Welch t-test  1.01     0       0.967        1.06 t_res <-    bind_rows(     tidy(t.test(y ~ group, data = example_dat, var.equal = TRUE)),      tidy(t.test(y ~ group, data = example_dat))   ) %>%   mutate(     estimate = estimate1 - estimate2,      method = c(\"t-test\", \"Welch t-test\")   ) %>%   select(method, est = estimate, p_val = p.value, lower_bound = conf.low, upper_bound = conf.high) %>%   mutate_if(is.numeric, round, 5)  t_res #> # A tibble: 2 × 5 #>   method         est p_val lower_bound upper_bound #>   <chr>        <dbl> <dbl>       <dbl>       <dbl> #> 1 t-test        1.01     0       0.967        1.06 #> 2 Welch t-test  1.01     0       0.967        1.06"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"convergence-issues","dir":"Articles","previous_headings":"Estimation Methods","what":"Convergence Issues","title":"Simulation Workflow","text":"estimate complicated models, like structural equation modeling hierarchical linear modeling, may cases model converge. handle cases, can add ...else statement within estimate() function evaluates whether model converged converge, statement outputs NA values estimates, p-values etc.","code":"estimate <- function(dat, design_parameters){      # write estimation models here   # e.g., fit_mimic <- lavaan::cfa(...)         # convergence    if(fit_mimic@optim$converged == FALSE){  # this syntax will depend on how the specific model stores convergence     res <- tibble(method = method, est = NA, p_val = NA,                    lower_bound = NA, upper_bound = NA)   } else{     res <- tibble(method = method, est = est, p_val = p_val,                    lower_bound = ci[1], upper_bound = ci[2])   }      return(res)  }"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"performance-summaries","dir":"Articles","previous_headings":"","what":"Performance Summaries","title":"Simulation Workflow","text":"step, create function calculate performance measures based results extracted estimation step, repeated across many replications. skeleton indicates, performance summary function takes results, along model parameters, returns dataset performance measures. function fills calc_performance() function. use calc_rejection() function simhelpers package calculate rejection rates.","code":"calc_performance <- function(results, model_params) {    return(performance_measures) } calc_performance <- function(results) {      performance_measures <- results %>%     group_by(method) %>%     group_modify(~ calc_rejection(.x, p_values = p_val))    return(performance_measures) }"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"simulation-driver","dir":"Articles","previous_headings":"","what":"Simulation Driver","title":"Simulation Workflow","text":"following code chunk sets simulation driver. arguments specify number iterations simulation parameters needed run data-generating estimating functions. function generates many sets results repeating data-generating step estimation step. Finally, function calculates performance measures returns results set parameters. driver example simulation study:","code":"run_sim <- function(iterations, model_params, design_params, seed = NULL) {   if (!is.null(seed)) set.seed(seed)    results <-     rerun(iterations, {       dat <- generate_dat(model_params)       estimate(dat, design_params)     }) %>%     bind_rows()    calc_performance(results, model_params) } run_sim <- function(iterations, n1, n2, mean_diff, seed = NULL) {   if (!is.null(seed)) set.seed(seed)    results <-     rerun(iterations, {       dat <- generate_dat(n1 = n1, n2 = n2, mean_diff = mean_diff)       estimate(dat = dat, n1 = n1, n2 = n2)     }) %>%     bind_rows()      calc_performance(results)  }"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"experimental-design-revisit","dir":"Articles","previous_headings":"","what":"Experimental Design Revisit","title":"Simulation Workflow","text":"Now functions order, can specify exact factors want manipulate study. following code chunk creates list design factors uses cross_df() function purrr package create every combination factor levels. also set number iterations seed used generating data (Wickham et al., 2019). code specifies three design factors: n1, specifies sample size Group 1, n2, specifies sample size Group 2, mean_diff, denotes mean difference two groups outcome. simulation factors. within-simulation factor t-test method one assuming equal variance one assuming equal variance.","code":"set.seed(20150316) # change this seed value!  # now express the simulation parameters as vectors/lists  design_factors <- list(factor1 = , factor2 = , ...) # combine into a design set  params <-   cross_df(design_factors) %>%   mutate(     iterations = 1000,  # change this to how many ever iterations       seed = round(runif(1) * 2^30) + 1:n()   )  # All look right? lengths(design_factors) nrow(params) head(params) set.seed(20200110)  # now express the simulation parameters as vectors/lists  design_factors <- list(   n1 = 50,   n2 = c(50, 70),   mean_diff = c(0, .5, 1, 2) ) params <-   cross_df(design_factors) %>%   mutate(     iterations = 1000,     seed = round(runif(1) * 2^30) + 1:n()   ) #> Warning: `cross_df()` was deprecated in purrr 1.0.0. #> ℹ Please use `tidyr::expand_grid()` instead. #> ℹ See <https://github.com/tidyverse/purrr/issues/768>. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated.   # All look right? lengths(design_factors) #>        n1        n2 mean_diff  #>         1         2         4 nrow(params) #> [1] 8 head(params) #> # A tibble: 6 × 5 #>      n1    n2 mean_diff iterations      seed #>   <dbl> <dbl>     <dbl>      <dbl>     <dbl> #> 1    50    50       0         1000 204809087 #> 2    50    70       0         1000 204809088 #> 3    50    50       0.5       1000 204809089 #> 4    50    70       0.5       1000 204809090 #> 5    50    50       1         1000 204809091 #> 6    50    70       1         1000 204809092"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"running-the-simulation-in-serial","dir":"Articles","previous_headings":"","what":"Running the Simulation in Serial","title":"Simulation Workflow","text":"run simulation using purrr package serial workflow. use pmap() function purrr run run_sim() function condition specified params.","code":"system.time(   results <-      params %>%     mutate(       res = pmap(., .f = run_sim)     ) %>%     unnest(cols = res) ) #> Warning: There was 1 warning in `mutate()`. #> ℹ In argument: `res = pmap(., .f = run_sim)`. #> Caused by warning: #> ! `rerun()` was deprecated in purrr 1.0.0. #> ℹ Please use `map()` instead. #>   # Previously #> rerun(1000, { #> dat <- generate_dat(n1 = n1, n2 = n2, mean_diff = mean_diff) #> estimate(dat = dat, n1 = n1, n2 = n2) #> }) #>  #>   # Now #> map(1:1000, ~ { #> dat <- generate_dat(n1 = n1, n2 = n2, mean_diff = mean_diff) #> estimate(dat = dat, n1 = n1, n2 = n2) #> }) #>    user  system elapsed  #>  22.681   0.004  22.687  results %>%   kable()"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"running-the-simulation-in-parallel","dir":"Articles","previous_headings":"","what":"Running the Simulation in Parallel","title":"Simulation Workflow","text":"use future furrr packages run simulation parallel (Bengtsson, 2020; Vaughan & Dancho, 2018). packages designed work functions purrr package. line gets cluster set computer network. complicated network setups, please see documentation future package. cluster configured, can just replace pmap() purrr future_pmap() run simulation parallel. simhelpers package, function, evaluate_by_row(), implements furrr workflow automatically:","code":"plan(multisession) library(future) library(furrr)  plan(multisession) # choose an appropriate plan from the future package  system.time(   results <-     params %>%     mutate(res = future_pmap(., .f = run_sim)) %>%     unnest(cols = res) ) plan(multisession) results <- evaluate_by_row(params, run_sim)"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"example-from-simhelpers","dir":"Articles","previous_headings":"","what":"Example from simhelpers","title":"Simulation Workflow","text":"create_skeleton() function simhelpers package open untitled .R file outline skeleton functions needed run simulation study.","code":"create_skeleton()"},{"path":[]},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/visualization.html","id":"introduction-to-tipton-pustejovsky-2015","dir":"Articles","previous_headings":"","what":"Introduction to Tipton & Pustejovsky (2015)","title":"Presenting Results from Simulation Studies","text":"vignette, provide brief example present report results simulation study. replicate Figure 2 Tipton & Pustejovsky (2015), examined several small sample corrections robust variance estimation methods used meta-analysis. Meta-analysis set statistical tools synthesizing results multiple primary studies common topic. Three major goals meta-analysis include summarizing results across studies using form effect size measure, characterizing amount variation effects, explaining variation effect sizes (Hedges, Tipton, & Johnson, 2010). Primary studies often report multiple estimates effect sizes resulting multiple correlated measures outcome, repeated measures outcome data comparison multiple treatment groups control group (Hedges et al., 2010). scenarios result statistical dependence effect sizes study. However, typical methods conduct meta-analysis, averaging effect sizes analyzing moderating effects meta-regression, involve assumption effect size independent. Use methods ignore dependence can result inaccurate standard errors therefore, hypothesis tests incorrect Type 1 error rates confidence intervals incorrect coverage levels (Becker, 2000). One alternative, using multivariate model, explicitly models correlations among effect size estimates (Hedges et al., 2010; Tipton, 2015). However, multivariate meta-analysis requires knowledge correlations covariances pairs effect sizes within primary study often difficult obtain (Olkin & Gleser, 2009). Hedges et al. (2010) proposed use robust variance estimation (RVE) handle dependent effect sizes. RVE require knowledge covariance structure effect sizes like multivariate analyses. Instead, RVE estimates variances meta-regression model’s coefficients using sandwich estimators (Hedges et al., 2010; Tipton, 2015). RVE increasingly used applied meta-analyses (Tipton, 2015). However, performance characteristics RVE asymptotic requires large number clusters (studies) provide accurate standard errors (Cameron, Gelbach, & Miller, 2008; Tipton, 2015). number studies meta-analysis small, basic RVE can result downwardly biased standard errors inflation Type 1 error rates (Cameron et al., 2008; Hedges et al., 2010; Tipton, 2015). Tipton (2015) Tipton & Pustejovsky (2015) introduced small sample corrections RVE tests single coefficients multiple contrast hypotheses, respectively. Tipton & Pustejovsky (2015) studied five methods, two based eigen decomposition three based Hotelling’s \\(T^2\\) distribution. authors recommended method (AHZ) approximates test statistic using Hotelling’s \\(T^2\\) distribution degrees freedom proposed Zhang (2012) Zhang (2013). method resulted Type 1 error rates closest nominal rate .05. However, AHZ shown still nominal Type 1 error rates tests multiple contrast hypotheses.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/visualization.html","id":"the-tipton_pusto-dataset","dir":"Articles","previous_headings":"","what":"The Tipton_Pusto Dataset","title":"Presenting Results from Simulation Studies","text":"simphelpers package includes dataset, Tipton_Pusto, containing subset simulation results Tipton & Pustejovsky (2015). Specifically, dataset contains results replicate Figure 2 article. dataset contains: num_studies: number studies contained meta-analysis used generate data. r: correlation outcomes result dependence. Isq: measure heterogeneity true effects. contrast: type contrast tested. test: small sample method used. EDF EDT two methods using eigen decomposition AHA, AHB AHZ three methods based Hotelling’s \\(T^2\\) distribution. q: number parameters hypothesis test. rej_rate: Type 1 error rate value nominal \\(\\alpha\\) set .05. mcse: Monte Carlo standard error Type 1 error rate. glimpse dataset:","code":"library(simhelpers) library(ggplot2) library(dplyr) library(knitr) library(kableExtra) glimpse(Tipton_Pusto) #> Rows: 15,300 #> Columns: 8 #> $ num_studies <dbl> 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10… #> $ r           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… #> $ Isq         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… #> $ contrast    <chr> \"O:2:23\", \"O:2:23\", \"O:2:23\", \"O:2:23\", \"O:2:23\", \"O:2:24\"… #> $ test        <fct> AHA, AHB, AHZ, EDF, EDT, AHA, AHB, AHZ, EDF, EDT, AHA, AHB… #> $ q           <chr> \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\"… #> $ rej_rate    <dbl> 0.0000, 0.0000, 0.0036, 0.0750, 0.0323, 0.0000, 0.0000, 0.… #> $ mcse        <dbl> 0.0000000000, 0.0000000000, 0.0005989190, 0.0026339134, 0.…"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/visualization.html","id":"data-cleaning","dir":"Articles","previous_headings":"","what":"Data Cleaning","title":"Presenting Results from Simulation Studies","text":"clean dataset visualization. add q = front value \\(q\\) add m = front value number studies.","code":"Tipton_Pusto <- Tipton_Pusto %>%   mutate(q_graph = paste(\"q = \", q),          m = paste(\"m = \", num_studies))"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/visualization.html","id":"visualization","dir":"Articles","previous_headings":"","what":"Visualization","title":"Presenting Results from Simulation Studies","text":"graph Type 1 error rates. error rate mapped onto y axis, small sample method mapped onto x axis, method also mapped color filling different methods different colors. add dashed line nominal \\(\\alpha\\) level .05. create boxplots capture range Type 1 error rates method across conditions examined simulation. facet number studies, m, number parameters used hypothesis test, q.","code":"Tipton_Pusto %>%   ggplot(aes(x = test, y = rej_rate, fill = test)) +    geom_hline(yintercept = .05, linetype = \"dashed\") +    geom_boxplot(alpha = .5) +    facet_grid(q_graph ~ m, scales = \"free\") +    labs(x = \"Method\", y = \"Type 1 Error Rate\", caption = \"FIGURE 2. Type I error rate for alpha of .05 of five alternative tests. Dashed lines indicate the nominal alpha level.\") +    theme_bw() +   theme(legend.position = \"none\",         plot.caption=element_text(hjust = 0, size = 10))"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/visualization.html","id":"interpretation-of-results","dir":"Articles","previous_headings":"","what":"Interpretation of Results","title":"Presenting Results from Simulation Studies","text":"write-results Tipton & Pustejovsky (2015): Figure 2 reveals several trends. First, Type error EDF EDT tests typically approach nominal values , whereas AHA, AHB, AHZ tests approach nominal values . trend holds relation \\(m\\) \\(q\\). example, 20 studies, \\(q\\) increases, Type error rates EDF EDT tests increase values far nominal (close .10), error rates decrease toward 0 AHA, AHB, AHZ tests. value \\(q\\), error rates five tests converge toward nominal values number studies increases. Second, EDF EDT tests Type error rates cover wide range values across parameters hypothesis specifications study (indicated long whiskers box). possible know priori design condition particular analysis fall, makes sense compare maximum Type error observed across tests. EDT EDF tests Type error rates closest nominal average, also exhibit error rates far nominal large number design conditions identified priori. comparison, AHA, AHB, AHZ tests typically conservative also nearly always level-\\(\\alpha\\), maximum error rate 0.059 across conditions studied. describing trends, therefore focus three AH tests.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/visualization.html","id":"monte-carlo-standard-error","dir":"Articles","previous_headings":"","what":"Monte Carlo Standard Error","title":"Presenting Results from Simulation Studies","text":"calculate maximum Monte Carlo standard error (MCSE) methods presented graph . Ideally, MCSE values relatively small compared estimated Type 1 error rates. Overall, maximum MCSEs small compared range reported rejection rates.","code":"Tipton_Pusto %>%   group_by(test) %>%   summarize(mcse = max(mcse)) %>%   kable(digits = 4)"},{"path":[]},{"path":"https://meghapsimatrix.github.io/simhelpers/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Megha Joshi. Author, maintainer. James Pustejovsky. Author.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Joshi M, Pustejovsky J (2024). simhelpers: Helper Functions Simulation Studies. R package version 0.2.0, https://meghapsimatrix.github.io/simhelpers/index.html.","code":"@Manual{,   title = {simhelpers: Helper Functions for Simulation Studies},   author = {Megha Joshi and James Pustejovsky},   year = {2024},   note = {R package version 0.2.0},   url = {https://meghapsimatrix.github.io/simhelpers/index.html}, }"},{"path":"https://meghapsimatrix.github.io/simhelpers/index.html","id":"simhelpers","dir":"","previous_headings":"","what":"Helper Functions for Simulation Studies","title":"Helper Functions for Simulation Studies","text":"Monte Carlo simulations computer experiments designed study performance statistical methods known data-generating conditions (Morris, White, & Crowther, 2019). Methodologists use simulations examine questions : (1) ordinary least squares regression perform errors heteroskedastic? (2) presence missing data affect treatment effect estimates propensity score analysis? (3) cluster robust variance estimation perform number clusters small? answer questions, conduct experiments simulating thousands datasets based pseudo-random sampling, applying statistical methods, evaluating well statistical methods recover true data-generating conditions (Morris et al., 2019). goal simhelpers assist running simulation studies. main tools package consist functions calculate measures estimator performance like bias, root mean squared error, rejection rates. functions also calculate associated Monte Carlo standard errors (MCSE) performance measures. functions divided three major categories performance criteria: absolute criteria, relative criteria, criteria evaluate hypothesis testing. functions use tidyeval principles, play well dplyr fit easily %>%-centric workflow (Wickham et al., 2019). addition set functions calculates performance measures MCSE, package also includes function, create_skeleton(), generates skeleton outline simulation study. Another function, evaluate_by_row(), runs simulation combination conditions row row. function uses future_pmap() furrr package, making easy run simulation parallel (Vaughan & Dancho, 2018). package also includes several datasets contain results example simulation studies.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Helper Functions for Simulation Studies","text":"Install latest release CRAN: Install development version GitHub:","code":"install.packages(\"simhelpers\") # install.packages(\"devtools\") devtools::install_github(\"meghapsimatrix/simhelpers\")"},{"path":"https://meghapsimatrix.github.io/simhelpers/index.html","id":"related-work","dir":"","previous_headings":"","what":"Related Work","title":"Helper Functions for Simulation Studies","text":"explanation MCSE formulas general simulation workflow closely aligned approach described Morris et al. (2019). want recognize several R packages offer functionality conducting Monte Carlo simulation studies. particular, rsimsum package (lovely name makes hungry) also calculates Monte Carlo standard errors (Gasparini, 2018). SimDesign package implements generate-analyze-summarize model writing simulations; also includes tools error handling parallel computing (Chalmers, 2019). contrast two packages mentioned , package uses tidyeval outputs tibbles, can easily used dplyr, tidyr purrr syntax (Wickham et al., 2019). functions calculate MCSEs easy run grouped data. parallel computing, use furrr future packages (Bengtsson, 2020; Vaughan & Dancho, 2018). Moreover, contrast rsimsum SimDesign packages, simhelpers provides jack-knife MCSE variance estimators. also provides jack-knife MCSE estimates root mean squared error. Another related project DeclareDesign, suite packages allow users declare diagnose research designs, fabricate mock data, explore tradeoffs different designs (Blair et al., 2019). project follows similar model simulation studies instantiated, uses higher-level API, tailored simulating certain specific types research designs. contrast, package simpler set general-purpose utility functions. packages similar aims simhelpers include: MonteCarlo, parSim, simsalapar, simulator, simstudy, simTool, simSummary, ezsim.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/index.html","id":"acknowledgments","dir":"","previous_headings":"","what":"Acknowledgments","title":"Helper Functions for Simulation Studies","text":"grateful feedback provided Danny Gonzalez, Sangdon Lim, Man Chen, Edouard Bonneville.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Helper Functions for Simulation Studies","text":"Bengtsson, H. (2020). future: Unified parallel distributed processing r everyone. Retrieved https://CRAN.R-project.org/package=future Blair, G., Cooper, J., Coppock, ., & Humphreys, M. (2019). Declaring diagnosing research designs. American Political Science Review, 113(3), 838–859. Retrieved https://declaredesign.org/paper.pdf Chalmers, P. (2019). SimDesign: Structure organizing Monte Carlo simulation designs. Retrieved https://CRAN.R-project.org/package=SimDesign Gasparini, . (2018). rsimsum: Summarise results Monte Carlo simulation studies. Journal Open Source Software, 3(26), 739. https://doi.org/10.21105/joss.00739 Morris, T. P., White, . R., & Crowther, M. J. (2019). Using simulation studies evaluate statistical methods. Statistics Medicine, 38(11), 2074–2102. Vaughan, D., & Dancho, M. (2018). furrr: Apply mapping functions parallel using futures. Retrieved https://CRAN.R-project.org/package=furrr Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., … Yutani, H. (2019). Welcome tidyverse. Journal Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/Tipton_Pusto.html","id":null,"dir":"Reference","previous_headings":"","what":"Results for Figure 2 of Tipton & Pustejovsky (2015) — Tipton_Pusto","title":"Results for Figure 2 of Tipton & Pustejovsky (2015) — Tipton_Pusto","text":"dataset containing simulation results comparing small sample correction methods cluster robust variance estimation meta-analysis.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/Tipton_Pusto.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Results for Figure 2 of Tipton & Pustejovsky (2015) — Tipton_Pusto","text":"","code":"Tipton_Pusto"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/Tipton_Pusto.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Results for Figure 2 of Tipton & Pustejovsky (2015) — Tipton_Pusto","text":"tibble 15,300 rows 8 variables: num_studies number studies included meta-analysis. r correlation outcomes. Isq measure heterogeneity true effects. contrast type contrast tested. test small sample method used. q number parameters hypothesis test. rej_rate Type 1 error rate. mcse Monte Carlo standard error estimate Type 1 error rate.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/Tipton_Pusto.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Results for Figure 2 of Tipton & Pustejovsky (2015) — Tipton_Pusto","text":"Tipton E, Pustejovsky JE (2015). “Small-Sample Adjustments Tests Moderators Model Fit Using Robust Variance Estimation Meta-Regression.” Journal Educational Behavioral Statistics, 40(6), 604--634. ISSN 1076-9986, 1935-1054, doi:10.3102/1076998615606099 , https://journals.sagepub.com/doi/10.3102/1076998615606099.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/alpha_res.html","id":null,"dir":"Reference","previous_headings":"","what":"Cronbach's alpha simulation results — alpha_res","title":"Cronbach's alpha simulation results — alpha_res","text":"dataset containing simulation results estimating Cronbach's alpha variance.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/alpha_res.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cronbach's alpha simulation results — alpha_res","text":"","code":"alpha_res"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/alpha_res.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cronbach's alpha simulation results — alpha_res","text":"tibble 1,000 rows 3 variables: estimate alpha. Var_A estimate variance alpha. true_param true alpha used generate data.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bundle_sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Bundle functions into a simulation driver function — bundle_sim","title":"Bundle functions into a simulation driver function — bundle_sim","text":"Bundle data-generation function, data-analysis function,   (optionally) performance summary function simulation driver.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bundle_sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bundle functions into a simulation driver function — bundle_sim","text":"","code":"bundle_sim(   f_generate,   f_analyze,   f_summarize = NULL,   reps_name = \"reps\",   seed_name = \"seed\",   summarize_opt_name = \"summarize\",   row_bind_reps = TRUE )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bundle_sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bundle functions into a simulation driver function — bundle_sim","text":"f_generate function data-generation f_analyze function data-analysis. first argument must data, format generated f_analyze(). f_summarize function calculating performance summaries across replications. first argument must replicated data analysis results. Default NULL, summary function used. reps_name character string set name argument number replications, default value \"reps\". seed_name character string set name argument seed option, default value \"seed\". Set NULL remove argument simulation driver. summarize_opt_name character string set name argument apply f_summarize simulation results, default value TRUE. Ignored f_summarize function specified. Set NULL remove argument simulation driver. row_bind_reps logical indicating whether combine simulation results data frame using rbind(), default value TRUE. FALSE, function return replications list f_summarize must able take list first argument.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bundle_sim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bundle functions into a simulation driver function — bundle_sim","text":"function repeatedly run `f_generate` `f_analyze`   functions (optionally) apply `f_summarize` resulting   replications.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bundle_sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bundle functions into a simulation driver function — bundle_sim","text":"","code":"f_G <- rnorm f_A <- function(x, trim = 0) data.frame(y_bar = mean(x, trim = trim)) f_S <- function(x, calc_sd = FALSE) {   if (calc_sd) {     res_SD <- apply(x, 2, sd)     res <- data.frame(M = colMeans(x), SD = res_SD)   } else {     res <- data.frame(M = colMeans(x))   }   res }  # bundle data-generation and data-analysis functions sim1 <- bundle_sim(f_generate = f_G, f_analyze = f_A) args(sim1) #> function (reps, n, mean = 0, sd = 1, trim = 0, seed = NA_real_)  #> NULL res1 <- sim1(4, n = 70, mean = 0.5, sd = 1, trim = 0.2) res1 #>       y_bar #> 1 0.5969869 #> 2 0.4302720 #> 3 0.6563275 #> 4 0.3486741  # bundle data-generation, data-analysis, and performance summary functions sim2 <- bundle_sim(f_generate = f_G, f_analyze = f_A, f_summarize = f_S) args(sim2) #> function (reps, n, mean = 0, sd = 1, trim = 0, calc_sd = FALSE,  #>     seed = NA_real_, summarize = TRUE)  #> NULL res2 <- sim2(24, n = 7, mean = 0, sd = 1, trim = 0.2, calc_sd = TRUE) res2 #>                 M        SD #> y_bar -0.06744114 0.3263067  # bundle data-generation and data-analysis functions, returning results as a list sim3 <- bundle_sim(f_generate = f_G, f_analyze = f_A, row_bind_reps = FALSE) args(sim3) #> function (reps, n, mean = 0, sd = 1, trim = 0, seed = NA_real_)  #> NULL res3 <- sim3(4, n = 70, mean = 0.5, sd = 3, trim = 0.2) res3 #> [[1]] #>       y_bar #> 1 0.3010377 #>  #> [[2]] #>      y_bar #> 1 0.762851 #>  #> [[3]] #>       y_bar #> 1 0.2372686 #>  #> [[4]] #>       y_bar #> 1 0.7449895 #>"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_absolute.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate absolute performance criteria and MCSE — calc_absolute","title":"Calculate absolute performance criteria and MCSE — calc_absolute","text":"Calculates absolute bias, variance, mean squared error (mse) root mean squared error (rmse). function also calculates associated Monte Carlo standard errors.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_absolute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate absolute performance criteria and MCSE — calc_absolute","text":"","code":"calc_absolute(   res_dat,   estimates,   true_param,   perfm_criteria = c(\"bias\", \"variance\", \"mse\", \"rmse\") )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_absolute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate absolute performance criteria and MCSE — calc_absolute","text":"res_dat data frame tibble containing simulation results. estimates name column containing estimates. true_param name column containing true parameters. perfm_criteria character character vector indicating performance criteria calculated.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_absolute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate absolute performance criteria and MCSE — calc_absolute","text":"tibble containing number simulation iterations, performance criteria estimate(s) associated MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_absolute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate absolute performance criteria and MCSE — calc_absolute","text":"","code":"calc_absolute(res_dat = t_res, estimates = est, true_param = true_param) #> # A tibble: 1 × 9 #>       K    bias bias_mcse    var var_mcse    mse mse_mcse  rmse rmse_mcse #>   <int>   <dbl>     <dbl>  <dbl>    <dbl>  <dbl>    <dbl> <dbl>     <dbl> #> 1  1000 0.00233   0.00638 0.0407  0.00183 0.0407  0.00183 0.202   0.00556"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_coverage.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate confidence interval coverage, width and MCSE — calc_coverage","title":"Calculate confidence interval coverage, width and MCSE — calc_coverage","text":"Calculates confidence interval coverage width. function also calculates associated Monte Carlo standard errors. confidence interval percentage based calculated lower upper bounds.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_coverage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate confidence interval coverage, width and MCSE — calc_coverage","text":"","code":"calc_coverage(   res_dat,   lower_bound,   upper_bound,   true_param,   perfm_criteria = c(\"coverage\", \"width\") )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_coverage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate confidence interval coverage, width and MCSE — calc_coverage","text":"res_dat data frame tibble containing simulation results. lower_bound name column containing lower bound estimates confidence intervals. upper_bound name column containing upper bound estimates confidence intervals. true_param name column containing true parameters. perfm_criteria character character vector indicating performance criteria calculated.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_coverage.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate confidence interval coverage, width and MCSE — calc_coverage","text":"tibble containing number simulation iterations, performance criteria estimate(s) associated MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_coverage.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate confidence interval coverage, width and MCSE — calc_coverage","text":"","code":"calc_coverage(res_dat = t_res, lower_bound = lower_bound,               upper_bound = upper_bound, true_param = true_param) #> # A tibble: 1 × 5 #>       K coverage coverage_mcse width width_mcse #>   <int>    <dbl>         <dbl> <dbl>      <dbl> #> 1  1000    0.951       0.00683 0.791    0.00179"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_rejection.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate rejection rate and MCSE — calc_rejection","title":"Calculate rejection rate and MCSE — calc_rejection","text":"Calculates rejection rate. function also calculates associated Monte Carlo standard error.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_rejection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate rejection rate and MCSE — calc_rejection","text":"","code":"calc_rejection(res_dat, p_values, alpha = 0.05)"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_rejection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate rejection rate and MCSE — calc_rejection","text":"res_dat data frame tibble containing simulation results. p_values name column containing p-values. alpha number indicating nominal alpha level. Default value set conventional .05.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_rejection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate rejection rate and MCSE — calc_rejection","text":"tibble containing number simulation iterations, performance criteria estimate associated MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_rejection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate rejection rate and MCSE — calc_rejection","text":"","code":"calc_rejection(res_dat = t_res, p_values = p_val) #> # A tibble: 1 × 3 #>       K rej_rate rej_rate_mcse #>   <int>    <dbl>         <dbl> #> 1  1000    0.702        0.0145"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate relative performance criteria and MCSE — calc_relative","title":"Calculate relative performance criteria and MCSE — calc_relative","text":"Calculates relative bias, mean squared error (relative mse), root mean squared error (relative rmse). function also calculates associated Monte Carlo standard errors.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate relative performance criteria and MCSE — calc_relative","text":"","code":"calc_relative(   res_dat,   estimates,   true_param,   perfm_criteria = c(\"relative bias\", \"relative mse\", \"relative rmse\") )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate relative performance criteria and MCSE — calc_relative","text":"res_dat data frame tibble containing simulation results. estimates name column containing estimates. true_param name column containing true parameters. perfm_criteria character character vector indicating performance criteria calculated.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate relative performance criteria and MCSE — calc_relative","text":"tibble containing number simulation iterations, performance criteria estimate(s) associated MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate relative performance criteria and MCSE — calc_relative","text":"","code":"calc_relative(res_dat = t_res, estimates = est, true_param = true_param) #> # A tibble: 1 × 7 #>       K rel_bias rel_bias_mcse rel_mse rel_mse_mcse rel_rmse rel_rmse_mcse #>   <int>    <dbl>         <dbl>   <dbl>        <dbl>    <dbl>         <dbl> #> 1  1000     1.00        0.0128   0.163      0.00366    0.403       0.00911"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate jack-knife Monte Carlo SE for variance estimators — calc_relative_var","title":"Calculate jack-knife Monte Carlo SE for variance estimators — calc_relative_var","text":"Calculates relative bias, mean squared error (relative mse), root mean squared error (relative rmse)  variance estimators. function also calculates associated jack-knife Monte Carlo standard errors.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate jack-knife Monte Carlo SE for variance estimators — calc_relative_var","text":"","code":"calc_relative_var(   res_dat,   estimates,   var_estimates,   perfm_criteria = c(\"relative bias\", \"relative mse\", \"relative rmse\") )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate jack-knife Monte Carlo SE for variance estimators — calc_relative_var","text":"res_dat data frame tibble containing simulation results. estimates name column containing estimates. var_estimates name column containing variance estimates. perfm_criteria character character vector indicating performance criteria calculated.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate jack-knife Monte Carlo SE for variance estimators — calc_relative_var","text":"tibble containing number simulation iterations, performance criteria estimate(s) associated MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative_var.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate jack-knife Monte Carlo SE for variance estimators — calc_relative_var","text":"","code":"calc_relative_var(res_dat = alpha_res, estimates = A, var_estimates = Var_A) #> # A tibble: 1 × 7 #>       K rel_bias_var rel_bias_var_mcse rel_mse_var rel_mse_var_mcse rel_rmse_var #>   <int>        <dbl>             <dbl>       <dbl>            <dbl>        <dbl> #> 1  1000        0.440             0.101       0.726            0.337        0.852 #> # ℹ 1 more variable: rel_rmse_var_mcse <dbl>"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/create_skeleton.html","id":null,"dir":"Reference","previous_headings":"","what":"Open a simulation skeleton — create_skeleton","title":"Open a simulation skeleton — create_skeleton","text":"Creates opens .R file containing skeleton writing Monte Carlo simulation study.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/create_skeleton.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Open a simulation skeleton — create_skeleton","text":"","code":"create_skeleton()"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/create_skeleton.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Open a simulation skeleton — create_skeleton","text":"","code":"if (FALSE) { create_skeleton() }"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/evaluate_by_row.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate a simulation function on each row of a data frame or tibble — evaluate_by_row","title":"Evaluate a simulation function on each row of a data frame or tibble — evaluate_by_row","text":"Evaluates simulation function row data frame tibble   containing parameter values. Returns single tibble parameters   simulation results. function uses furrr::future_pmap,   allows easy parallelization.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/evaluate_by_row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate a simulation function on each row of a data frame or tibble — evaluate_by_row","text":"","code":"evaluate_by_row(   params,   sim_function,   ...,   results_name = \".results\",   .progress = FALSE,   .options = furrr::furrr_options(),   system_time = TRUE )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/evaluate_by_row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate a simulation function on each row of a data frame or tibble — evaluate_by_row","text":"params data frame tibble containing simulation parameter values. row represent separate set parameter values. sim_function function evaluated, argument names matching variable names params. function must return data.frame, tibble, vector. ... additional arguments passed sim_function. results_name character string set name column storing results simulation. Default \".results\". .progress single logical. progress bar displayed? works multisession, multicore, multiprocess futures. Note multicore/multisession future falls back sequential, progress bar displayed. Warning: .progress argument deprecated removed future version furrr favor using robust progressr package. .options future specific options use workers. must result call furrr_options(). system_time logical indicating whether print computation time. TRUE default.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/evaluate_by_row.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate a simulation function on each row of a data frame or tibble — evaluate_by_row","text":"tibble containing parameter values simulation results.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/evaluate_by_row.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate a simulation function on each row of a data frame or tibble — evaluate_by_row","text":"","code":"df <- data.frame(   n = 3:5,   lambda = seq(8, 16, 4) )  evaluate_by_row(df, rpois) #> Warning: UNRELIABLE VALUE: Future (‘<none>’) unexpectedly generated random numbers without specifying argument 'seed'. There is a risk that those random numbers are not statistically sound and the overall results might be invalid. To fix this, specify 'seed=TRUE'. This ensures that proper, parallel-safe random numbers are produced via the L'Ecuyer-CMRG method. To disable this check, use 'seed=NULL', or set option 'future.rng.onMisuse' to \"ignore\". #>    user  system elapsed  #>   0.044   0.000   0.043  #> # A tibble: 12 × 3 #>        n lambda .results #>    <int>  <dbl>    <int> #>  1     3      8        7 #>  2     3      8        8 #>  3     3      8       11 #>  4     4     12        9 #>  5     4     12       11 #>  6     4     12        9 #>  7     4     12       10 #>  8     5     16       10 #>  9     5     16       12 #> 10     5     16       18 #> 11     5     16       12 #> 12     5     16       17"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/t_res.html","id":null,"dir":"Reference","previous_headings":"","what":"t-test simulation results — t_res","title":"t-test simulation results — t_res","text":"dataset containing simulation results study just runs t-test.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/t_res.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"t-test simulation results — t_res","text":"","code":"t_res"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/t_res.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"t-test simulation results — t_res","text":"tibble 1,000 rows 5 variables: est estimate mean difference. p_val p-value t-test. lower_bound lower bound confidence interval. upper_bound upper bound confidence interval. true_param true mean difference used generate data.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/welch_res.html","id":null,"dir":"Reference","previous_headings":"","what":"Welch t-test simulation results — welch_res","title":"Welch t-test simulation results — welch_res","text":"dataset containing simulation results study comparing Welch t-test conventional t-test.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/welch_res.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Welch t-test simulation results — welch_res","text":"","code":"welch_res"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/welch_res.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Welch t-test simulation results — welch_res","text":"tibble 16,000 rows 11 variables: n1 sample size Group 1. n2 sample size Group 2. mean_diff true difference means two groups used generate data. iterations number iterations. seed seed used generate data. method indicates whether Welch conventional t-test used. est estimate mean difference. var variance estimate. p_val p-value t-test. lower_bound lower bound confidence interval. upper_bound upper bound confidence interval.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/news/index.html","id":"simhelpers-020","dir":"Changelog","previous_headings":"","what":"simhelpers 0.2.0","title":"simhelpers 0.2.0","text":"Added new, experimental function bundle_sim() compose set functions simulation driver. Added argument evaluate_by_row() control name variable simulation results stored.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/news/index.html","id":"simhelpers-012","dir":"Changelog","previous_headings":"","what":"simhelpers 0.1.2","title":"simhelpers 0.1.2","text":"CRAN release: 2022-05-03 Removed import defunct function furrr package.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/news/index.html","id":"simhelpers-011","dir":"Changelog","previous_headings":"","what":"simhelpers 0.1.1","title":"simhelpers 0.1.1","text":"CRAN release: 2021-02-14 Fixed formula jacknife MCSE","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/news/index.html","id":"simhelpers-010","dir":"Changelog","previous_headings":"","what":"simhelpers 0.1.0","title":"simhelpers 0.1.0","text":"CRAN release: 2020-03-31 First version","code":""}]
