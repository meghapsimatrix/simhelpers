[{"path":[]},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"absolute-criteria","dir":"Articles","previous_headings":"Performance Criteria and MCSE","what":"Absolute Criteria","title":"Simulation Performance Criteria and MCSE","text":"Bias characterizes whether estimator tends lie true parameter, average. Variance characterizes precision estimator, average squared deviation estimator average. Note variance inverse precision. Therefore, higher variance, lower precision. Standard error, also characterizing precision, square root variance. Mean squared error (MSE) root mean squared error (RMSE) characterize accuracy estimates. MSE RMSE measure far , average, estimator true parameter. Absolute criteria scale estimate. MSE squared deviation scale RMSE scale estimates. Let TT denote estimator parameter θ\\theta. running simulation study, obtain KK estimates T1,...,TKT_1,...,T_K (realizations estimator) data generating condition. can calculate following sample statistics estimates: Sample mean: T‾=1K∑k=1KTk\\bar{T} = \\frac{1}{K}\\sum_{k=1}^K T_k Sample variance: ST2=1K−1∑k=1K(Tk−T‾)2S_T^2 = \\frac{1}{K - 1}\\sum_{k=1}^K \\left(T_k - \\bar{T}\\right)^2 Sample skewness (standardized): gT=1KST3∑k=1K(Tk−T‾)3g_T = \\frac{1}{K S_T^3}\\sum_{k=1}^K \\left(T_k - \\bar{T}\\right)^3 Sample kurtosis (standardized): kT=1KST4∑k=1K(Tk−T‾)4k_T = \\frac{1}{K S_T^4} \\sum_{k=1}^K \\left(T_k - \\bar{T}\\right)^4 Table 1 shows performance criteria, interpretation, formal definition, criterion estimated simulation study, formula MCSE estimated performance measure. Table 1. Absolute Performance Criteria equation MCSE standard deviation derived using jack-knife technique (Efron & Stein, 1981). First calculate variance estimates leaving replicate jj. Instead calculating jack-knife estimate, use algebraic tricks calculate ST(j)2S^2_{T(j)} follows: ST(j)2=1K−2[(K−1)ST2−KK−1(Tj−T‾)2]S_{T(j)}^2 = \\frac{1}{K - 2} \\left[(K - 1) S_T^2 - \\frac{K}{K - 1}\\left(T_j - \\bar{T}\\right)^2\\right] , jack-knife MCSE standard deviation calculated : K−1K∑j=1K(ST(j)2−ST)2\\sqrt{\\frac{K - 1}{K} \\sum_{j=1}^K (\\sqrt{S_{T(j)}^2} - S_T)^2 } equation MCSE RMSE also derived using jack-knife technique, involves excluding replicate jj calculating RMSE (Efron & Stein, 1981). formula RMSE : 1K∑k=1K(Tk−θ)2\\sqrt{\\frac{1}{K}\\sum_{k=1}^{K}\\left(T_k - \\theta\\right)^2} approximately equivalent : RMSE=(T‾−θ)2+ST2RMSE = \\sqrt{(\\bar{T} - \\theta)^2 + S^2_T} jack-knife RMSE calculated : RMSE(j)=(T‾(j)−θ)2+ST(j)2RMSE_{(j)}  = \\sqrt{(\\bar{T}_{(j)} - \\theta)^2 + S^2_{T(j)}} T‾(j)\\bar{T}_{(j)} ST(j)2S^2_{T(j)} indicate mean variance estimates leaving replicate jj. Instead calculating jack-knife estimate, use algebraic tricks calculate T‾(j)\\bar{T}_{(j)} ST(j)2S^2_{T(j)} follows: T‾(j)=1K−1(KT‾−Tj)\\bar{T}_{(j)} = \\frac{1}{K-1} \\left(K \\bar{T} - T_j\\right) ST(j)2=1K−2[(K−1)ST2−KK−1(Tj−T‾)2]S_{T(j)}^2 = \\frac{1}{K - 2} \\left[(K - 1) S_T^2 - \\frac{K}{K - 1}\\left(T_j - \\bar{T}\\right)^2\\right] , jack-knife MCSE RMSE calculated : MCSERMSE(JK)=K−1K∑j=1K(RMSE(j)−RMSE)2MCSE_{RMSE(JK)}  = \\sqrt{\\frac{K -1}{K}\\sum_{j=1}^K  \\left(RMSE_{(j)} - RMSE\\right)^2}","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"example","dir":"Articles","previous_headings":"Performance Criteria and MCSE > Absolute Criteria","what":"Example","title":"Simulation Performance Criteria and MCSE","text":"use welch_res dataset included package. contains results example simulation study comparing heteroskedasticity-robust Welch t-test usual two-sample t-test assuming equal variances. code used generate data derive results can found . varied sample sizes per group. set sample size Group 1 50 varied sample size Group 2 50 70. varied mean difference parameter generating data two groups. set values 0, 0.5, 1 2. generated data slightly unequal variances. simulated dataset, ran usual t-test, assumes homogeneity variance, also ran Welch t-test, assume homogeneity variance. extracted estimates (mean differences), variances estimates, p-values, lower upper bounds confidence intervals. , calculate absolute performance criteria estimates mean differences. present results sample sizes, mean difference, t-test method. calc_absolute() function designed work tidyeval workflow (Wickham et al., 2019). first argument, res_dat, requires data frame tibble containing results simulation study. second argument, estimates, requires name column containing estimates like mean difference regression coefficients. third argument, true_param, requires name column containing true parameters. fourth argument, perfm_criteria, lets user specify criteria evaluate. criteria can specified using character character vector. user wants bias, can specify perfm_criteria = \"bias\". user wants bias root mean squared error, can specify perfm_criteria = c(\"bias\", \"rmse\"). default, function returns bias, variance, standard error, mean squared error (mse), root mean squared error (rmse), perfm_criteria = c(\"bias\", \"variance\", \"stddev\", \"mse\", \"rmse\"). example , ask available criteria. calculate absolute performance measures conventional t-test results mean difference identical Welch t-test. use dplyr syntax group sample sizes mean difference used generate data. provide examples using () group_modify() run calc_absolute() results combination conditions. Results rounded five decimal places. convergence issues estimation, please make sure write estimation function output NA values point estimates, variance estimates, p-values, confidence interval estimates. functions simhelpers package calculate performance criteria MCSE deleting missing estimates output number iterations, K, exclude iterations NA values estimates. Note K may differ condition.","code":"library(simhelpers) library(dplyr) library(tibble) library(knitr) library(dplyr) library(kableExtra)  welch_res %>%   glimpse() #> Rows: 16,000 #> Columns: 11 #> $ n1          <dbl> 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50… #> $ n2          <dbl> 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50… #> $ mean_diff   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… #> $ iterations  <dbl> 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000… #> $ seed        <dbl> 204809087, 204809087, 204809087, 204809087, 204809087, 204… #> $ method      <chr> \"t-test\", \"Welch t-test\", \"t-test\", \"Welch t-test\", \"t-tes… #> $ est         <dbl> 0.025836000, 0.025836000, 0.005158587, 0.005158587, -0.079… #> $ var         <dbl> 0.09543914, 0.09543914, 0.08481717, 0.08481717, 0.08179330… #> $ p_val       <dbl> 0.9335212, 0.9335804, 0.9859039, 0.9859109, 0.7807543, 0.7… #> $ lower_bound <dbl> -0.5872300, -0.5899041, -0.5727856, -0.5741984, -0.6473703… #> $ upper_bound <dbl> 0.6389020, 0.6415761, 0.5831027, 0.5845155, 0.4877263, 0.4… # using do() welch_res %>%   filter(method == \"t-test\") %>% # filter just conventional t-test res   group_by(n1, n2, mean_diff) %>% # grouping    do(calc_absolute(., estimates = est, true_param = mean_diff)) %>% # run the function   kable(digits = 5) # create a kable table # using group_modify() welch_res %>%   filter(method == \"t-test\") %>% # filter just conventional t-test res   mutate(params = mean_diff) %>% # group_modify cannot take in a group column as an argument   group_by(n1, n2, mean_diff) %>% # grouping    group_modify(~ calc_absolute(.x, estimates = est, true_param = params)) %>%   kable(digits = 5)"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"relative-criteria","dir":"Articles","previous_headings":"Performance Criteria and MCSE","what":"Relative Criteria","title":"Simulation Performance Criteria and MCSE","text":"Relative criteria can useful describing estimator’s performance, especially performance varies proportion true value target parameter. can used |θ|>0|\\theta| > 0 divide 00(Morris et al., 2019). derive MCSE relative RMSE, used jack-knife technique. formula calculate relative RMSE : rRMSE=(T‾−θ)2+ST2θ2rRMSE = \\sqrt{\\frac{(\\bar{T} - \\theta)^2 + S_T^2}{\\theta^2}} jack-knife RMSE calculated : rRMSE(j)=(T‾(j)−θ)2+ST(j)2θ2rRMSE_{(j)}  = \\sqrt{\\frac{(\\bar{T}_{(j)} - \\theta)^2 + S_{T(j)}^2}{\\theta^2}} T‾(j)\\bar{T}_{(j)} ST(j)2S^2_{T(j)} calculated specified described algebra trick estimate values. MCSE calculated specified table . Table 2 shows relative performance criteria, interpretation, formal definition, criterion estimated simulation study, MCSE formula. Table 2. Relative Performance Criteria","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"example-1","dir":"Articles","previous_headings":"Performance Criteria and MCSE > Relative Criteria","what":"Example","title":"Simulation Performance Criteria and MCSE","text":", calculate relative criteria mean difference estimates. Note mean difference 0, relative measures calculated function returns NA values. syntax calc_relative() similar one used earlier calc_absolute(). perfm_criteria argument allows user specify criteria evaluate: perfm_criteria = c(\"relative bias\", \"relative mse\", \"relative rmse\").","code":"# using group_modify() welch_res %>%   filter(method == \"t-test\") %>%   mutate(params = mean_diff) %>%   group_by(n1, n2, mean_diff) %>%   group_modify(~ calc_relative(.x, estimates = est, true_param = params)) %>%   kable(digits = 5)"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"relative-criteria-for-variance-estimators","dir":"Articles","previous_headings":"Performance Criteria and MCSE","what":"Relative Criteria for Variance Estimators","title":"Simulation Performance Criteria and MCSE","text":"Variance estimators always positive, relative criteria often used characterize performance. variance estimators, VV denoting sampling variance point estimator TT. assess relative criteria VV, need divide true value sampling variance TT, λ=Var(T)\\lambda = \\text{Var}(T), may able calculate directly. scenario, can use sample variance TT across replications, ST2S_T^2, estimate true sampling variance. relative bias estimated rB=V‾/ST2rB = \\bar{V} / S_T^2, average variance estimates divided sample variance point estimates. estimate MCSE relative bias variance estimator, need account uncertainty estimation true sampling variance. One way use jack-knife technique described , entails excluding replicate jj calculating relative bias V‾(j)/ST(j)2\\bar{V}_{(j)}/ S_{T(j)}^2. Monte Carlo standard error can calculated : MCSE(rB)=K−1K∑j=1K(rB(j)−rB)2 MCSE\\left(rB\\right) = \\sqrt{\\frac{K - 1}{K} \\sum_{j=1}^K \\left(rB_{(j)} - rB\\right)^2}  can written : MCSE(rB)=K−1K∑j=1K(V‾(j)ST(j)2−V‾ST2)2 MCSE\\left(rB\\right) = \\sqrt{\\frac{K - 1}{K} \\sum_{j=1}^K \\left(\\frac{\\bar{V}_{(j)}}{S_{T(j)}^2} - \\frac{\\bar{V}}{S_T^2}\\right)^2} reformulate MCSE using algebra tricks similar reformulated RMSE MCSE formulas . V‾(j)=1K−1(KV‾−Vj)ST(j)2=1K−2[(K−1)ST2−KK−1(Tj−T‾)2] \\begin{aligned} \\bar{V}_{(j)} &= \\frac{1}{K - 1}\\left(K \\bar{V} - V_j\\right) \\\\ S_{T(j)}^2 &= \\frac{1}{K - 2} \\left[(K - 1) S_T^2 - \\frac{K}{K - 1}\\left(T_j - \\bar{T}\\right)^2\\right] \\end{aligned} Similarly, can estimate MCSE relative MSE RMSE using jack-knife technique. estimate MSE need estimate SV(j)2S_{V(j)}^2, represents sample variance variance estimates leaving replicate jj . calculate SV(j)2S_{V(j)}^2 SV(j)2=1K−2[(K−1)SV2−KK−1(Vj−V‾)2].S_{V(j)}^2 = \\frac{1}{K - 2} \\left[(K - 1) S_V^2 - \\frac{K}{K - 1}\\left(V_j - \\bar{V}\\right)^2\\right]. can estimate jack-knife relative MSE RMSE following logic described calculate MCSE. Table 3 lists relative performance measures variance estimators. Table 3. Relative Performance Criteria Variance Estimators function calc_relative_var() calculates relative performance criteria estimates corresponding jack-knife MCSEs variance estimator. function requires res_dat, data frame tibble containing simulation results, estimates, name column containing point estimates, var_estimates, name column containing variance estimates, perfm_criteria, criteria evaluated: perfm_criteria = c(\"relative bias\", \"relative mse\", \"relative rmse\"). demonstrate use calc_relative_var() function. variance estimates expected different derived conventional t-test opposed derived Welch t-test. group sample sizes, mean difference, t-test method. Note difference conventional t-test Welch t-test results, especially group sample sizes unequal. convergence issues estimation, please make sure estimation function returns NA values variance estimate point estimate. calc_relative_var() function omit pair point estimate variance estimate either value NA calculating performance measure MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"example-2","dir":"Articles","previous_headings":"Performance Criteria and MCSE > Relative Criteria for Variance Estimators","what":"Example","title":"Simulation Performance Criteria and MCSE","text":"","code":"welch_res %>%   group_by(n1, n2, mean_diff, method) %>%   group_modify(~ calc_relative_var(.x, estimates = est, var_estimates = var)) %>%   kable(digits = 5)"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"hypothesis-testing-and-confidence-intervals","dir":"Articles","previous_headings":"Performance Criteria and MCSE","what":"Hypothesis Testing and Confidence Intervals","title":"Simulation Performance Criteria and MCSE","text":"hypothesis tests, often interested whether Type 1 error rate adequately controlled whether test enough power detect effect size substantive interest. rejection rate hypothesis test captures proportion times p-value specified α\\alpha level—, proportion times reject null hypothesis. specified effect size 0, can examine Type 1 error rates magnitude effect greater 0, can examine power. also interested confidence interval coverage, proportion intervals contain true parameter, interval width, indicator precision interval estimator. Table 4 presents performance criteria used evaluate hypothesis tests. table, let PkP_k denote p-value simulation replication kk, k=1,...,Kk = 1,...,K. Suppose confidence intervals target parameter θ\\theta coverage level β\\beta. Let AkA_k BkB_k denote lower upper end-points confidence interval simulation replication kk, let Wk=Bk−AkW_k = B_k − A_k, k=1,...,Kk = 1,...,K. Table 4. Hypothesis Testing Confidence Intervals Performance Criteria","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"example-3","dir":"Articles","previous_headings":"Performance Criteria and MCSE > Hypothesis Testing and Confidence Intervals","what":"Example","title":"Simulation Performance Criteria and MCSE","text":"calculate rejection rates hypothesis tests conducted using conventional two-sample t-test Welch t-test. null hypothesis two groups means. calc_rejection() function requires data frame tibble containing simulation results first argument. second argument, p_values, requires name column containing p-values. third argument, alpha, lets user specify value α\\alpha. default value set conventional 0.05. calculate confidence interval coverage rates widths estimates mean difference. calc_coverage() function requires data frame tibble containing simulation results first argument. second third arguments, lower_bound upper_bound, take name columns contain lower upper bound estimates confidence intervals. true_param argument requires name column containing true parameters. Like calc_absolute(), calc_relative() calc_relative_var(), calc_coverage() also argument, perfm_criteria, user can specify criteria evaluate: perfm_criteria = c(\"coverage\", \"width\").","code":"# using group_modify() welch_res %>%   group_by(n1, n2, mean_diff, method) %>%   group_modify(~ calc_rejection(.x, p_values = p_val)) %>%   kable(digits = 5) # using group_modify() welch_res %>%   mutate(params = mean_diff) %>%   group_by(n1, n2, mean_diff, method) %>%   group_modify(~ calc_coverage(.x, lower_bound = lower_bound, upper_bound = upper_bound, true_param = params)) %>%   kable(digits = 5)"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/MCSE.html","id":"how-to-evaluate-mcse","dir":"Articles","previous_headings":"","what":"How to Evaluate MCSE","title":"Simulation Performance Criteria and MCSE","text":"Generally, associated MCSE small compared performance measure. example Frane (2015) write MCSE results part simulation study results. Frane (2015) compared various methods control Type 1 error rates conducting analysis multiple outcome variables. describing simulation results, wrote: Bonferroni MP strictly controlled PFER; observed maximum PFER 0.050 Bonferroni, 0.051 Sidák, 0.061 Holm, 0.100 Hochberg, 0.050 MP (estimated SE ≤ 0.0002 estimates). PFER refers per family error rate, expected number Type 1 errors mm comparisons. MP refers multivariate analysis variance (MANOVA) protected tests. SE refers MCSE. number replications 1,000,000 Frane (2015). note number quite high generally 1,000 10,000 replications enough. resulting MCSEs Frane (2015), therefore, exceedingly small compared values PFER. information performance criteria MCSE, recommend Morris et al. (2019).","code":""},{"path":[]},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"initial-experimental-design","dir":"Articles","previous_headings":"","what":"Initial Experimental Design","title":"Simulation Workflow","text":"begin working simulation study, decide model design parameters want vary. Parameters can include sample size, proportion missing data etc.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"data-generating-model","dir":"Articles","previous_headings":"","what":"Data Generating Model","title":"Simulation Workflow","text":"data-generating function takes model parameters. example, can generate data varying sample size level heteroskedasticity amount missingness. skeleton data-generating function. arguments data-generating parameters want vary. example generate random normal data two groups, second group standard deviation twice large first group. function takes three arguments: n1, indicating sample size Group 1, n2 indicating sample size Group 2, mean_diff, indicating mean difference. creating data-generating function, check whether works. , generate example dataset 10,000 people group mean_diff set 1. , create summary table. mean outcome Group 1 close 1 mean Group 2 close 0. standard deviation outcome Group 1 close 1 standard deviation Group 2 close 2. table matches specified data-generating model. create density plot values generated groups. distributions seem normal. peaks seem difference 1. , variances outcome scores different group specified.","code":"generate_dat <- function(model_params) {    return(dat) } generate_dat <- function(n1, n2, mean_diff){    dat <- tibble(     y = c(rnorm(n = n1, mean_diff, 1), # mean diff as mean, sd 1           rnorm(n = n2, 0, 2)), # mean 0, sd 2     group = c(rep(\"Group 1\", n1), rep(\"Group 2\", n2))   )    return(dat)  } set.seed(2020143) example_dat <- generate_dat(n1 = 10000, n2= 10000, mean_diff = 1)   example_dat %>%   head() #> # A tibble: 6 × 2 #>        y group   #>    <dbl> <chr>   #> 1  0.491 Group 1 #> 2 -0.534 Group 1 #> 3  1.02  Group 1 #> 4  0.754 Group 1 #> 5  0.762 Group 1 #> 6  0.979 Group 1 example_dat %>%   group_by(group) %>%   summarize(n = n(),             M = mean(y),             SD = sd(y)) %>%   kable(digits = 3) ggplot(example_dat, aes(x = y, fill = group)) +    geom_density(alpha = .5) +    labs(x = \"Outcome Scores\", y = \"Density\", fill = \"Group\") +    theme_bw() +   theme(legend.position = c(0.9, 0.8)) #> Warning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2 #> 3.5.0. #> ℹ Please use the `legend.position.inside` argument of `theme()` instead. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated."},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"estimation-methods","dir":"Articles","previous_headings":"","what":"Estimation Methods","title":"Simulation Workflow","text":"step, run statistical methods calculate test statistics, regression coefficients, p-values, confidence intervals. function takes data design parameters, options estimation carried (e.g., use HC0 standard errors HC2 standard errors). example function runs t-tests simulated dataset. function runs conventional t-test, assumes homogeneity variance, Welch t-test, assume population variances outcome two groups equal. function returns tibble containing names two methods, mean difference estimates, p-values, upper lower bounds confidence intervals. use t.test() function extract everything need. function implements calculations directly (using sample statistics) mostly just fun. reason t.test() function lot extra stuff handle contingencies come real data (like missing observations), unnecessary running calculations simulated data. , good check function runs . run estimate() function example dataset: can compare results built-t.test() function: values match.","code":"estimate <- function(dat, design_params) {    return(results) } # t and p value calc_t <- function(est, vd, df, method){    se <- sqrt(vd)  # standard error    t <- est / se # t-test    p_val <-  2 * pt(-abs(t), df = df) # p value   ci <- est + c(-1, 1) * qt(.975, df = df) * se # confidence interval      res <- tibble(method = method, est = est, p_val = p_val,                  lower_bound = ci[1], upper_bound = ci[2])    return(res) }   estimate <- function(dat, n1, n2){    # calculate summary stats   means <- tapply(dat$y, dat$group, mean)   vars <- tapply(dat$y, dat$group, var)    # calculate summary stats   est <- means[1] - means[2] # mean diff   var_1 <- vars[1] # var for group 1   var_2 <- vars[2] # var for group 2    # conventional t-test   dft <- n1 + n2 - 2  # degrees of freedom   sp_sq <- ((n1 - 1) * var_1 + (n2 - 1) * var_2) / dft  # pooled var   vdt <- sp_sq * (1 / n1 + 1 / n2) # variance of estimate    # welch t-test   dfw <- (var_1 / n1 + var_2 / n2)^2 / (((1 / (n1 - 1)) * (var_1 / n1)^2) + ((1 / (n2 - 1)) * (var_2 / n2)^2))  # degrees of freedom    vdw <- var_1 / n1 + var_2 / n2 # variance of estimate    results <- bind_rows(calc_t(est = est, vd = vdt, df = dft, method = \"t-test\"),                    calc_t(est = est, vd = vdw, df = dfw, method = \"Welch t-test\"))     return(results)  } est_res <-    estimate(example_dat, n1 = 10000, n2 = 10000) %>%   mutate_if(is.numeric, round, 5)  est_res #> # A tibble: 2 × 5 #>   method         est p_val lower_bound upper_bound #>   <chr>        <dbl> <dbl>       <dbl>       <dbl> #> 1 t-test        1.01     0       0.967        1.06 #> 2 Welch t-test  1.01     0       0.967        1.06 t_res <-    bind_rows(     tidy(t.test(y ~ group, data = example_dat, var.equal = TRUE)),      tidy(t.test(y ~ group, data = example_dat))   ) %>%   mutate(     estimate = estimate1 - estimate2,      method = c(\"t-test\", \"Welch t-test\")   ) %>%   select(method, est = estimate, p_val = p.value, lower_bound = conf.low, upper_bound = conf.high) %>%   mutate_if(is.numeric, round, 5)  t_res #> # A tibble: 2 × 5 #>   method         est p_val lower_bound upper_bound #>   <chr>        <dbl> <dbl>       <dbl>       <dbl> #> 1 t-test        1.01     0       0.967        1.06 #> 2 Welch t-test  1.01     0       0.967        1.06"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"convergence-issues","dir":"Articles","previous_headings":"Estimation Methods","what":"Convergence Issues","title":"Simulation Workflow","text":"estimate complicated models, like structural equation modeling hierarchical linear modeling, may cases model converge. handle cases, can add ...else statement within estimate() function evaluates whether model converged converge, statement outputs NA values estimates, p-values etc.","code":"estimate <- function(dat, design_parameters){      # write estimation models here   # e.g., fit_mimic <- lavaan::cfa(...)         # convergence    if(fit_mimic@optim$converged == FALSE){  # this syntax will depend on how the specific model stores convergence     res <- tibble(method = method, est = NA, p_val = NA,                    lower_bound = NA, upper_bound = NA)   } else{     res <- tibble(method = method, est = est, p_val = p_val,                    lower_bound = ci[1], upper_bound = ci[2])   }      return(res)  }"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"performance-summaries","dir":"Articles","previous_headings":"","what":"Performance Summaries","title":"Simulation Workflow","text":"step, create function calculate performance measures based results extracted estimation step, repeated across many replications. skeleton indicates, performance summary function takes results, along model parameters, returns dataset performance measures. function fills calc_performance() function. use calc_rejection() function simhelpers package calculate rejection rates.","code":"calc_performance <- function(results, model_params) {    return(performance_measures) } calc_performance <- function(results) {      performance_measures <- results %>%     group_by(method) %>%     group_modify(~ calc_rejection(.x, p_values = p_val))    return(performance_measures) }"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"simulation-driver","dir":"Articles","previous_headings":"","what":"Simulation Driver","title":"Simulation Workflow","text":"following code chunk sets simulation driver. arguments specify number iterations simulation parameters needed run data-generating estimating functions. function generates many sets results repeating data-generating step estimation step. Finally, function calculates performance measures returns results set parameters. driver example simulation study:","code":"run_sim <- function(iterations, model_params, design_params, seed = NULL) {   if (!is.null(seed)) set.seed(seed)    results <-     map_dfr(1:iterations, ~ {       dat <- generate_dat(model_params)       estimate(dat, design_params)     })    calc_performance(results, model_params) } run_sim <- function(iterations, n1, n2, mean_diff, seed = NULL) {   if (!is.null(seed)) set.seed(seed)    results <-     map_dfr(1:iterations, ~ {       dat <- generate_dat(n1 = n1, n2 = n2, mean_diff = mean_diff)       estimate(dat = dat, n1 = n1, n2 = n2)     })      calc_performance(results)  }"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"experimental-design-revisit","dir":"Articles","previous_headings":"","what":"Experimental Design Revisit","title":"Simulation Workflow","text":"Now functions order, can specify exact factors want manipulate study. following code chunk creates list design factors uses expand_grid() function tidyr package create every combination factor levels. also set number iterations seed used generating data (Wickham et al., 2019). code specifies three design factors: n1, specifies sample size Group 1, n2, specifies sample size Group 2, mean_diff, denotes mean difference two groups outcome. simulation factors. within-simulation factor t-test method one assuming equal variance one assuming equal variance.","code":"set.seed(20150316) # change this seed value!  # now express the simulation parameters as vectors/lists  design_factors <- list(factor1 = , factor2 = , ...) # combine into a design set  params <-   tidyr::expand_grid(!!!design_factors) %>%   mutate(     iterations = 1000,  # change this to how many ever iterations       seed = round(runif(1) * 2^30) + 1:n()   )  # All look right? lengths(design_factors) nrow(params) head(params) set.seed(20200110)  # now express the simulation parameters as vectors/lists  design_factors <- list(   n1 = 50,   n2 = c(50, 70),   mean_diff = c(0, .5, 1, 2) ) params <-   tidyr::expand_grid(!!!design_factors) %>%   mutate(     iterations = 1000,     seed = round(runif(1) * 2^30) + 1:n()   )   # All look right? lengths(design_factors) #>        n1        n2 mean_diff  #>         1         2         4 nrow(params) #> [1] 8 head(params) #> # A tibble: 6 × 5 #>      n1    n2 mean_diff iterations      seed #>   <dbl> <dbl>     <dbl>      <dbl>     <dbl> #> 1    50    50       0         1000 204809087 #> 2    50    50       0.5       1000 204809088 #> 3    50    50       1         1000 204809089 #> 4    50    50       2         1000 204809090 #> 5    50    70       0         1000 204809091 #> 6    50    70       0.5       1000 204809092"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"running-the-simulation-in-serial","dir":"Articles","previous_headings":"","what":"Running the Simulation in Serial","title":"Simulation Workflow","text":"run simulation using purrr package serial workflow. use pmap() function purrr run run_sim() function condition specified params.","code":"system.time(   results <-      params %>%     mutate(       res = pmap(., .f = run_sim)     ) %>%     unnest(cols = res) ) #>    user  system elapsed  #>  23.384   0.000  23.386  results %>%   kable()"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"running-the-simulation-in-parallel","dir":"Articles","previous_headings":"","what":"Running the Simulation in Parallel","title":"Simulation Workflow","text":"use future furrr packages run simulation parallel (Bengtsson, 2020; Vaughan & Dancho, 2018). packages designed work functions purrr package. line gets cluster set computer network. complicated network setups, please see documentation future package. cluster configured, can just replace pmap() purrr future_pmap() run simulation parallel. simhelpers package, function, evaluate_by_row(), implements furrr workflow automatically:","code":"plan(multisession) library(future) library(furrr)  plan(multisession) # choose an appropriate plan from the future package  system.time(   results <-     params %>%     mutate(res = future_pmap(., .f = run_sim)) %>%     unnest(cols = res) ) plan(multisession) results <- evaluate_by_row(params, run_sim)"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/simulation_workflow.html","id":"example-from-simhelpers","dir":"Articles","previous_headings":"","what":"Example from simhelpers","title":"Simulation Workflow","text":"create_skeleton() function simhelpers package open untitled .R file outline skeleton functions needed run simulation study.","code":"create_skeleton()"},{"path":[]},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/visualization.html","id":"introduction-to-tipton-pustejovsky-2015","dir":"Articles","previous_headings":"","what":"Introduction to Tipton & Pustejovsky (2015)","title":"Presenting Results from Simulation Studies","text":"vignette, provide brief example present report results simulation study. replicate Figure 2 Tipton & Pustejovsky (2015), examined several small sample corrections robust variance estimation methods used meta-analysis. Meta-analysis set statistical tools synthesizing results multiple primary studies common topic. Three major goals meta-analysis include summarizing results across studies using form effect size measure, characterizing amount variation effects, explaining variation effect sizes (Hedges, Tipton, & Johnson, 2010). Primary studies often report multiple estimates effect sizes resulting multiple correlated measures outcome, repeated measures outcome data comparison multiple treatment groups control group (Hedges et al., 2010). scenarios result statistical dependence effect sizes study. However, typical methods conduct meta-analysis, averaging effect sizes analyzing moderating effects meta-regression, involve assumption effect size independent. Use methods ignore dependence can result inaccurate standard errors therefore, hypothesis tests incorrect Type 1 error rates confidence intervals incorrect coverage levels (Becker, 2000). One alternative, using multivariate model, explicitly models correlations among effect size estimates (Hedges et al., 2010; Tipton, 2015). However, multivariate meta-analysis requires knowledge correlations covariances pairs effect sizes within primary study often difficult obtain (Olkin & Gleser, 2009). Hedges et al. (2010) proposed use robust variance estimation (RVE) handle dependent effect sizes. RVE require knowledge covariance structure effect sizes like multivariate analyses. Instead, RVE estimates variances meta-regression model’s coefficients using sandwich estimators (Hedges et al., 2010; Tipton, 2015). RVE increasingly used applied meta-analyses (Tipton, 2015). However, performance characteristics RVE asymptotic requires large number clusters (studies) provide accurate standard errors (Cameron, Gelbach, & Miller, 2008; Tipton, 2015). number studies meta-analysis small, basic RVE can result downwardly biased standard errors inflation Type 1 error rates (Cameron et al., 2008; Hedges et al., 2010; Tipton, 2015). Tipton (2015) Tipton & Pustejovsky (2015) introduced small sample corrections RVE tests single coefficients multiple contrast hypotheses, respectively. Tipton & Pustejovsky (2015) studied five methods, two based eigen decomposition three based Hotelling’s T2T^2 distribution. authors recommended method (AHZ) approximates test statistic using Hotelling’s T2T^2 distribution degrees freedom proposed Zhang (2012) Zhang (2013). method resulted Type 1 error rates closest nominal rate .05. However, AHZ shown still nominal Type 1 error rates tests multiple contrast hypotheses.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/visualization.html","id":"the-tipton_pusto-dataset","dir":"Articles","previous_headings":"","what":"The Tipton_Pusto Dataset","title":"Presenting Results from Simulation Studies","text":"simphelpers package includes dataset, Tipton_Pusto, containing subset simulation results Tipton & Pustejovsky (2015). Specifically, dataset contains results replicate Figure 2 article. dataset contains: num_studies: number studies contained meta-analysis used generate data. r: correlation outcomes result dependence. Isq: measure heterogeneity true effects. contrast: type contrast tested. test: small sample method used. EDF EDT two methods using eigen decomposition AHA, AHB AHZ three methods based Hotelling’s T2T^2 distribution. q: number parameters hypothesis test. rej_rate: Type 1 error rate value nominal α\\alpha set .05. mcse: Monte Carlo standard error Type 1 error rate. glimpse dataset:","code":"library(simhelpers) library(ggplot2) library(dplyr) library(knitr) library(kableExtra) glimpse(Tipton_Pusto) #> Rows: 15,300 #> Columns: 8 #> $ num_studies <dbl> 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10… #> $ r           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… #> $ Isq         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… #> $ contrast    <chr> \"O:2:23\", \"O:2:23\", \"O:2:23\", \"O:2:23\", \"O:2:23\", \"O:2:24\"… #> $ test        <fct> AHA, AHB, AHZ, EDF, EDT, AHA, AHB, AHZ, EDF, EDT, AHA, AHB… #> $ q           <chr> \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\"… #> $ rej_rate    <dbl> 0.0000, 0.0000, 0.0036, 0.0750, 0.0323, 0.0000, 0.0000, 0.… #> $ mcse        <dbl> 0.0000000000, 0.0000000000, 0.0005989190, 0.0026339134, 0.…"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/visualization.html","id":"data-cleaning","dir":"Articles","previous_headings":"","what":"Data Cleaning","title":"Presenting Results from Simulation Studies","text":"clean dataset visualization. add q = front value qq add m = front value number studies.","code":"Tipton_Pusto <- Tipton_Pusto %>%   mutate(q_graph = paste(\"q = \", q),          m = paste(\"m = \", num_studies))"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/visualization.html","id":"visualization","dir":"Articles","previous_headings":"","what":"Visualization","title":"Presenting Results from Simulation Studies","text":"graph Type 1 error rates. error rate mapped onto y axis, small sample method mapped onto x axis, method also mapped color filling different methods different colors. add dashed line nominal α\\alpha level .05. create boxplots capture range Type 1 error rates method across conditions examined simulation. facet number studies, m, number parameters used hypothesis test, q.","code":"Tipton_Pusto %>%   ggplot(aes(x = test, y = rej_rate, fill = test)) +    geom_hline(yintercept = .05, linetype = \"dashed\") +    geom_boxplot(alpha = .5) +    facet_grid(q_graph ~ m, scales = \"free\") +    labs(x = \"Method\", y = \"Type 1 Error Rate\", caption = \"FIGURE 2. Type I error rate for alpha of .05 of five alternative tests. Dashed lines indicate the nominal alpha level.\") +    theme_bw() +   theme(legend.position = \"none\",         plot.caption=element_text(hjust = 0, size = 10))"},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/visualization.html","id":"interpretation-of-results","dir":"Articles","previous_headings":"","what":"Interpretation of Results","title":"Presenting Results from Simulation Studies","text":"write-results Tipton & Pustejovsky (2015): Figure 2 reveals several trends. First, Type error EDF EDT tests typically approach nominal values , whereas AHA, AHB, AHZ tests approach nominal values . trend holds relation mm qq. example, 20 studies, qq increases, Type error rates EDF EDT tests increase values far nominal (close .10), error rates decrease toward 0 AHA, AHB, AHZ tests. value qq, error rates five tests converge toward nominal values number studies increases. Second, EDF EDT tests Type error rates cover wide range values across parameters hypothesis specifications study (indicated long whiskers box). possible know priori design condition particular analysis fall, makes sense compare maximum Type error observed across tests. EDT EDF tests Type error rates closest nominal average, also exhibit error rates far nominal large number design conditions identified priori. comparison, AHA, AHB, AHZ tests typically conservative also nearly always level-α\\alpha, maximum error rate 0.059 across conditions studied. describing trends, therefore focus three AH tests.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/articles/visualization.html","id":"monte-carlo-standard-error","dir":"Articles","previous_headings":"","what":"Monte Carlo Standard Error","title":"Presenting Results from Simulation Studies","text":"calculate maximum Monte Carlo standard error (MCSE) methods presented graph . Ideally, MCSE values relatively small compared estimated Type 1 error rates. Overall, maximum MCSEs small compared range reported rejection rates.","code":"Tipton_Pusto %>%   group_by(test) %>%   summarize(mcse = max(mcse)) %>%   kable(digits = 4)"},{"path":[]},{"path":"https://meghapsimatrix.github.io/simhelpers/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Megha Joshi. Author, maintainer. James Pustejovsky. Author.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Joshi M, Pustejovsky J (2025). simhelpers: Helper Functions Simulation Studies. R package version 0.3.1.9999, https://meghapsimatrix.github.io/simhelpers/.","code":"@Manual{,   title = {simhelpers: Helper Functions for Simulation Studies},   author = {Megha Joshi and James Pustejovsky},   year = {2025},   note = {R package version 0.3.1.9999},   url = {https://meghapsimatrix.github.io/simhelpers/}, }"},{"path":"https://meghapsimatrix.github.io/simhelpers/index.html","id":"simhelpers","dir":"","previous_headings":"","what":"Helper Functions for Simulation Studies","title":"Helper Functions for Simulation Studies","text":"Monte Carlo simulations computer experiments designed study performance statistical methods known data-generating conditions (Morris, White, & Crowther, 2019). Methodologists use simulations examine questions : (1) ordinary least squares regression perform errors heteroskedastic? (2) presence missing data affect treatment effect estimates propensity score analysis? (3) cluster robust variance estimation perform number clusters small? answer questions, conduct experiments simulating thousands datasets based pseudo-random sampling, applying statistical methods, evaluating well statistical methods recover true data-generating conditions (Morris et al., 2019). goal simhelpers assist running simulation studies. package includes two main tools. First, includes collection functions calculate measures estimator performance bias, root mean squared error, rejection rates, confidence interval coverage. functions also calculate associated Monte Carlo standard errors (MCSE) performance measures. functions divided three major categories performance criteria: absolute criteria, relative criteria, criteria evaluate hypothesis testing. functions designed play well dplyr fit easily %>%-centric workflow (Wickham et al., 2019). addition set functions calculates performance measures MCSE, package includes convenience functions assist programming simulations. include bundle_sim(), can used create single function running simulation component pieces. function takes function generating data, function analyzing data, (optionally) function summarizing results, constructs single function running full simulation given set parameter values optional arguments, call “simulation driver.” simulation driver function can applied parameter set using evaluate_by_row() execute simulations across multiple conditions. Finally, package also includes function, create_skeleton(), generates skeleton outline simulation study. Another function, evaluate_by_row(), runs simulation combination conditions row row. function uses future_pmap() furrr package, making easy run simulation parallel (Vaughan & Dancho, 2018). package also includes several datasets contain results example simulation studies.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Helper Functions for Simulation Studies","text":"Install latest release CRAN: Install development version GitHub:","code":"install.packages(\"simhelpers\") # install.packages(\"devtools\") devtools::install_github(\"meghapsimatrix/simhelpers\")"},{"path":"https://meghapsimatrix.github.io/simhelpers/index.html","id":"related-work","dir":"","previous_headings":"","what":"Related Work","title":"Helper Functions for Simulation Studies","text":"explanation MCSE formulas general simulation workflow closely aligned approach described Morris et al. (2019). want recognize several R packages offer functionality conducting Monte Carlo simulation studies. particular, rsimsum package (lovely name makes hungry) also calculates Monte Carlo standard errors (Gasparini, 2018). SimDesign package implements generate-analyze-summarize model writing simulations, provided inspiration bundle_sim() tools. SimDesign also includes tools error handling parallel computing (Chalmers, 2019). contrast two packages mentioned , package designed used dplyr, tidyr purrr syntax (Wickham et al., 2019). functions calculate MCSEs easy run grouped data. parallel computing, evaluate_by_row() uses furrr future packages (Bengtsson, 2020; Vaughan & Dancho, 2018). Moreover, contrast rsimsum SimDesign packages, simhelpers provides jack-knife MCSE variance estimators. also provides jack-knife MCSE estimates root mean squared error. Another related project DeclareDesign, suite packages allow users declare diagnose research designs, fabricate mock data, explore tradeoffs different designs (Blair et al., 2019). project follows similar model simulation studies instantiated, uses higher-level API, tailored simulating certain specific types research designs. contrast, package simpler set general-purpose utility functions. packages similar aims simhelpers include: MonteCarlo, parSim, simsalapar, simulator, simstudy, simTool, simSummary, ezsim.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/index.html","id":"acknowledgments","dir":"","previous_headings":"","what":"Acknowledgments","title":"Helper Functions for Simulation Studies","text":"grateful feedback provided Danny Gonzalez, Sangdon Lim, Man Chen, Edouard Bonneville.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Helper Functions for Simulation Studies","text":"Bengtsson, H. (2020). future: Unified parallel distributed processing r everyone. Retrieved https://CRAN.R-project.org/package=future Blair, G., Cooper, J., Coppock, ., & Humphreys, M. (2019). Declaring diagnosing research designs. American Political Science Review, 113(3), 838–859. Retrieved https://declaredesign.org/paper.pdf Chalmers, P. (2019). SimDesign: Structure organizing Monte Carlo simulation designs. Retrieved https://CRAN.R-project.org/package=SimDesign Gasparini, . (2018). rsimsum: Summarise results Monte Carlo simulation studies. Journal Open Source Software, 3(26), 739. https://doi.org/10.21105/joss.00739 Morris, T. P., White, . R., & Crowther, M. J. (2019). Using simulation studies evaluate statistical methods. Statistics Medicine, 38(11), 2074–2102. Vaughan, D., & Dancho, M. (2018). furrr: Apply mapping functions parallel using futures. Retrieved https://CRAN.R-project.org/package=furrr Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., … Yutani, H. (2019). Welcome tidyverse. Journal Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/Tipton_Pusto.html","id":null,"dir":"Reference","previous_headings":"","what":"Results for Figure 2 of Tipton & Pustejovsky (2015) — Tipton_Pusto","title":"Results for Figure 2 of Tipton & Pustejovsky (2015) — Tipton_Pusto","text":"dataset containing simulation results comparing small sample correction methods cluster robust variance estimation meta-analysis.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/Tipton_Pusto.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Results for Figure 2 of Tipton & Pustejovsky (2015) — Tipton_Pusto","text":"","code":"Tipton_Pusto"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/Tipton_Pusto.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Results for Figure 2 of Tipton & Pustejovsky (2015) — Tipton_Pusto","text":"tibble 15,300 rows 8 variables: num_studies number studies included meta-analysis. r correlation outcomes. Isq measure heterogeneity true effects. contrast type contrast tested. test small sample method used. q number parameters hypothesis test. rej_rate Type 1 error rate. mcse Monte Carlo standard error estimate Type 1 error rate.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/Tipton_Pusto.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Results for Figure 2 of Tipton & Pustejovsky (2015) — Tipton_Pusto","text":"Tipton E, Pustejovsky JE (2015). “Small-sample adjustments tests moderators model fit using robust variance estimation meta-regression.” Journal Educational Behavioral Statistics, 40(6), 604–634. doi:10.3102/1076998615606099 .","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/alpha_res.html","id":null,"dir":"Reference","previous_headings":"","what":"Cronbach's alpha simulation results — alpha_res","title":"Cronbach's alpha simulation results — alpha_res","text":"dataset containing simulation results estimating Cronbach's alpha variance.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/alpha_res.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cronbach's alpha simulation results — alpha_res","text":"","code":"alpha_res"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/alpha_res.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cronbach's alpha simulation results — alpha_res","text":"tibble 1,000 rows 3 variables: estimate alpha. Var_A estimate variance alpha. true_param true alpha used generate data.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_CIs.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate one or multiple bootstrap confidence intervals — bootstrap_CIs","title":"Calculate one or multiple bootstrap confidence intervals — bootstrap_CIs","text":"Calculate one multiple bootstrap confidence intervals, given   sample bootstrap replications.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_CIs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate one or multiple bootstrap confidence intervals — bootstrap_CIs","text":"","code":"bootstrap_CIs(   boot_est,   boot_se = NULL,   est = NULL,   se = NULL,   influence = NULL,   CI_type = \"percentile\",   level = 0.95,   B_vals = length(boot_est),   reps = 1L,   format = \"wide\",   seed = NULL )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_CIs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate one or multiple bootstrap confidence intervals — bootstrap_CIs","text":"boot_est vector bootstrap replications estimator. boot_se vector estimated standard errors bootstrap replication. est numeric value estimate based original sample. Required CI_type = \"normal\", CI_type = \"basic\", CI_type = \"student\", CI_type = \"bias-corrected\". se numeric value estimated standard error based original sample. Required CI_type = \"student\". influence vector empirical influence values estimator. Required CI_type = \"BCa\". CI_type Character string vector character strings indicating types confidence intervals calculate. Options \"normal\", \"basic\", \"student\", \"percentile\" (default), \"bias-corrected\", \"BCa\". level numeric value 0 1 desired coverage level, default 0.95. B_vals vector sub-sample sizes calculate confidence intervals. Setting B_vals = length(boot_est) (default) return bootstrap confidence intervals calculated full set bootstrap replications. B_vals < length(boot_est), confidence intervals calculated sub-sampling (without replacement) bootstrap replications. reps integer value number sub-sample confidence intervals generate B_vals < length(boot_est), default reps = 1. format character string controlling format output. format = \"wide\" (default), different types confidence intervals returned separate columns. format = \"long\", confidence intervals different types appear different rows dataset. format = \"wide-list\", different types confidence intervals returned separate columns result wrapped unnamed list. seed Single numeric value random number generator seed set. Default NULL, set seed.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_CIs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate one or multiple bootstrap confidence intervals — bootstrap_CIs","text":"format = \"wide\", function returns data.frame   reps rows per entry B_vals, row contains   confidence intervals one sub-sample replication. format = \"long\", function returns data.frame   one row CI_type, replication, entry   B_vals, row contains single confidence interval one   sub-sample replication. format = \"wide-list\", output structured   format = \"wide\" wrapped unnamed list, makes   easier sore output tibble, assigned class   \"bootstrap_CIs\".","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_CIs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate one or multiple bootstrap confidence intervals — bootstrap_CIs","text":"Confidence intervals calculated following methods described   Chapter 5 Davison Hinkley (1997). basic non-parametric   bootstraps, methods nearly identical implementation   boot.ci boot package.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_CIs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate one or multiple bootstrap confidence intervals — bootstrap_CIs","text":"Davison, .C. Hinkley, D.V. (1997). _Bootstrap Methods   Application_, Chapter 5. Cambridge University Press.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_CIs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate one or multiple bootstrap confidence intervals — bootstrap_CIs","text":"","code":"# generate t-distributed data N <- 50 mu <- 2 nu <- 5 dat <- mu + rt(N, df = nu)  # create bootstrap replications f <- \\(x) {  c(    M = mean(x, trim = 0.1),    SE = sd(x) / sqrt(length(x))  ) }  booties <- replicate(399, {   sample(dat, replace = TRUE, size = N) |>   f() })  res <- f(dat)  # calculate bootstrap CIs from full set of bootstrap replicates bootstrap_CIs(   boot_est = booties[1,],   boot_se = booties[2,],   est = res[1],   se = res[2],   CI_type = c(\"normal\",\"basic\",\"student\",\"percentile\",\"bias-corrected\"),   format = \"long\" ) #>   bootstraps           type    lower    upper #> 1        399         normal 2.028844 2.816268 #> 2        399          basic 2.040644 2.818643 #> 3        399        student 2.033162 2.870852 #> 4        399     percentile 2.022576 2.800575 #> 5        399 bias-corrected 2.022576 2.797262  # Calculate bias-corrected-and-accelerated CIs inf_vals <- res[1] - sapply(seq_along(dat), \\(i) f(dat[-i])[1]) bootstrap_CIs(   boot_est = booties[1,],   est = res[1],   influence = inf_vals,   CI_type = c(\"percentile\",\"bias-corrected\",\"BCa\"),   format = \"long\" ) #>   bootstraps           type    lower    upper #> 1        399     percentile 2.022576 2.800575 #> 2        399 bias-corrected 2.022576 2.797262 #> 3        399            BCa 2.022576 2.797262  # calculate multiple bootstrap CIs using sub-sampling of replicates bootstrap_CIs(   boot_est = booties[1,],   boot_se = booties[2,],   est = res[1],   se = res[2],   CI_type = c(\"normal\",\"basic\",\"student\",\"percentile\",\"bias-corrected\"),   B_vals = 199,   reps = 4L,   format = \"long\" ) #>    bootstraps           type    lower    upper #> 1         199         normal 2.031996 2.859805 #> 2         199          basic 2.044270 2.875748 #> 3         199        student 2.057285 2.957861 #> 4         199     percentile 1.965472 2.796949 #> 5         199 bias-corrected 2.001888 2.804617 #> 6         199         normal 2.021828 2.873832 #> 7         199          basic 1.999816 2.839331 #> 8         199        student 1.976411 2.885610 #> 9         199     percentile 2.001888 2.841403 #> 10        199 bias-corrected 2.051460 2.930256 #> 11        199         normal 2.001092 2.838692 #> 12        199          basic 2.044270 2.874536 #> 13        199        student 2.035858 2.948230 #> 14        199     percentile 1.966683 2.796949 #> 15        199 bias-corrected 1.966683 2.793398 #> 16        199         normal 2.016251 2.780760 #> 17        199          basic 2.043957 2.790233 #> 18        199        student 2.028818 2.876856 #> 19        199     percentile 2.050987 2.797262 #> 20        199 bias-corrected 2.001888 2.774727  # calculate multiple bootstrap CIs using sub-sampling of replicates, # for each of several sub-sample sizes. bootstrap_CIs(   boot_est = booties[1,],   boot_se = booties[2,],   est = res[1],   se = res[2],   CI_type = c(\"normal\",\"basic\",\"student\",\"percentile\"),   B_vals = c(49,99,199),   reps = 4L,   format = \"long\" ) #>    bootstraps       type    lower    upper #> 1          49     normal 2.000343 2.877043 #> 2          49      basic 2.036602 2.874536 #> 3          49    student 2.033162 2.948230 #> 4          49 percentile 1.966683 2.804617 #> 5          49     normal 2.031352 2.905860 #> 6          49      basic 2.043957 2.791094 #> 7          49    student 2.074542 2.823714 #> 8          49 percentile 2.050126 2.797262 #> 9          49     normal 2.020648 2.720565 #> 10         49      basic 2.050924 2.729620 #> 11         49    student 2.085570 2.699863 #> 12         49 percentile 2.111599 2.790295 #> 13         49     normal 2.043214 2.886938 #> 14         49      basic 2.138788 2.874536 #> 15         49    student 2.140775 2.885610 #> 16         49 percentile 1.966683 2.702431 #> 17         99     normal 2.067627 2.853661 #> 18         99      basic 2.047821 2.791094 #> 19         99    student 2.035858 2.846810 #> 20         99 percentile 2.050126 2.793398 #> 21         99     normal 2.002904 2.856506 #> 22         99      basic 2.031207 2.839331 #> 23         99    student 2.008973 2.957861 #> 24         99 percentile 2.001888 2.810012 #> 25         99     normal 2.032474 2.777077 #> 26         99      basic 2.072614 2.791663 #> 27         99    student 2.096600 2.948230 #> 28         99 percentile 2.049556 2.768605 #> 29         99     normal 2.008817 2.809936 #> 30         99      basic 1.969681 2.789759 #> 31         99    student 1.950793 2.876856 #> 32         99 percentile 2.051460 2.871538 #> 33        199     normal 2.018971 2.826070 #> 34        199      basic 2.044270 2.875748 #> 35        199    student 2.057285 2.885610 #> 36        199 percentile 1.965472 2.796949 #> 37        199     normal 2.026626 2.833965 #> 38        199      basic 2.036602 2.874536 #> 39        199    student 2.033162 2.915899 #> 40        199 percentile 1.966683 2.804617 #> 41        199     normal 2.021649 2.799257 #> 42        199      basic 2.040644 2.791094 #> 43        199    student 2.008973 2.866753 #> 44        199 percentile 2.050126 2.800575 #> 45        199     normal 2.023718 2.828731 #> 46        199      basic 2.040644 2.839331 #> 47        199    student 2.033162 2.885610 #> 48        199 percentile 2.001888 2.800575"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_pvals.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate one or multiple bootstrap p-values — bootstrap_pvals","title":"Calculate one or multiple bootstrap p-values — bootstrap_pvals","text":"Calculate one multiple bootstrap p-values, given bootstrap   sample test statistics.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_pvals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate one or multiple bootstrap p-values — bootstrap_pvals","text":"","code":"bootstrap_pvals(   boot_stat,   stat,   alternative = \"two-sided\",   B_vals = length(boot_stat),   reps = 1L,   enlist = FALSE,   seed = NULL )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_pvals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate one or multiple bootstrap p-values — bootstrap_pvals","text":"boot_stat vector bootstrap replications test statistic. stat numeric value test statistic based original sample. alternative character string specifying alternative hypothesis, must one \"two-sided\" (default), \"greater\" \"less\". B_vals vector sub-sample sizes calculate p-values. Setting B_vals = length(boot_stat) (default) return single p-value calculated full set bootstrap replications. B_vals < length(boot_stat), p-values calculated sub-sampling (without replacement) bootstrap replications. reps integer value number sub-sample p-values generate B_vals < length(boot_stat), default reps = 1. enlist logical indicating whether wrap returned values unnamed list, default FALSE. Setting enlist = TRUE makes easier store output single entry tibble. seed Single numeric value random number generator seed set. Default NULL, set seed.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_pvals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate one or multiple bootstrap p-values — bootstrap_pvals","text":"format output depends several contingencies.   single value B_vals specified reps = 1,   function returns vector single p-value. single value   B_vals specified B_vals < length(boot_stat)   reps > 1, function returns vector p-values, entry   sub-sample replication. B_vals vector multiple   values, function returns list one entry per entry   B_vals, entry vector length reps   entries sub-sample replication. enlist = TRUE, results wrapped unnamed list,   makes easier sore output tibble.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_pvals.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate one or multiple bootstrap p-values — bootstrap_pvals","text":"p-values calculated comparing stat distribution   boot_stat, taken represent null distribution   test statistic. alternative = \"two-sided\" (default),   p-value proportion bootstrap sample absolute   value bootstrapped statistic exceeds absolute value   original statistic. alternative = \"greater\", p-value   proportion bootstrap sample value bootstrapped   statistic larger original statistic. alternative =   \"less\", p-value proportion bootstrap sample   value bootstrapped statistic less original   statistic.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_pvals.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate one or multiple bootstrap p-values — bootstrap_pvals","text":"Davison, .C. Hinkley, D.V. (1997). _Bootstrap Methods   Application_, Chapter 4. Cambridge University Press.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bootstrap_pvals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate one or multiple bootstrap p-values — bootstrap_pvals","text":"","code":"# generate data from two distinct populations dat <- data.frame(   group = rep(c(\"A\",\"B\"), c(40, 50)),   y = c(     rgamma(40, shape = 7, scale = 2),     rgamma(50, shape = 3, scale = 4)   ) ) stat <- t.test(y ~ group, data = dat)$statistic  # create bootstrap replications under the null of no difference boot_dat <- dat booties <- replicate(399, {   boot_dat$group <- sample(dat$group)   t.test(y ~ group, data = boot_dat)$statistic })  # calculate bootstrap p-values from full set of bootstrap replicates bootstrap_pvals(boot_stat = booties, stat = stat) #>   bootstraps      pval #> 1        399 0.6917293  # calculate multiple bootstrap p-values using sub-sampling of replicates bootstrap_pvals(   boot_stat = booties, stat = stat,   B_vals = 199,   reps = 4L ) #>   bootstraps                                       pval #> 1        199 0.7085427, 0.7035176, 0.6633166, 0.6783920  # calculate multiple bootstrap p-values using sub-sampling of replicates, # for each of several sub-sample sizes. bootstrap_pvals(   boot_stat = booties, stat = stat,   B_vals = c(49,99,199),   reps = 4L ) #>   bootstraps                                       pval #> 1         49 0.6530612, 0.7551020, 0.6938776, 0.6734694 #> 2         99 0.6868687, 0.6363636, 0.6666667, 0.7070707 #> 3        199 0.6884422, 0.6884422, 0.6633166, 0.7286432"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bundle_sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Bundle functions into a simulation driver function — bundle_sim","title":"Bundle functions into a simulation driver function — bundle_sim","text":"Bundle data-generation function, data-analysis function,   (optionally) performance summary function simulation driver.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bundle_sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bundle functions into a simulation driver function — bundle_sim","text":"","code":"bundle_sim(   f_generate,   f_analyze,   f_summarize = NULL,   reps_name = \"reps\",   seed_name = \"seed\",   summarize_opt_name = \"summarize\",   stack_reps = TRUE,   id = NULL )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bundle_sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bundle functions into a simulation driver function — bundle_sim","text":"f_generate function data-generation f_analyze function data-analysis. first argument must data, format generated f_analyze(). f_summarize function calculating performance summaries across replications. first argument must replicated data analysis results. Default NULL, summary function used. reps_name character string set name argument number replications, default value \"reps\". seed_name character string set name argument seed option, default value \"seed\". Set NULL remove argument simulation driver. summarize_opt_name character string set name argument apply f_summarize simulation results, default value \"summarize\". Ignored f_summarize function specified. Set NULL remove argument simulation driver. stack_reps logical indicating whether combine simulation results data.frame, default value TRUE. FALSE, function return replications list f_summarize must able take list first argument. Passed repeat_and_stack(). id Character string use creating variable unique identifier repetition `f_generate` `f_analyze`. set NULL (default), identifier created. Passed repeat_and_stack().","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bundle_sim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bundle functions into a simulation driver function — bundle_sim","text":"function repeatedly run `f_generate` `f_analyze`   functions (optionally) apply `f_summarize` resulting   replications.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/bundle_sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bundle functions into a simulation driver function — bundle_sim","text":"","code":"f_G <- rnorm f_A <- function(x, trim = 0) data.frame(y_bar = mean(x, trim = trim)) f_S <- function(x, calc_sd = FALSE) {   if (calc_sd) {     res_SD <- apply(x, 2, sd)     res <- data.frame(M = colMeans(x), SD = res_SD)   } else {     res <- data.frame(M = colMeans(x))   }   res }  # bundle data-generation and data-analysis functions sim1 <- bundle_sim(f_generate = f_G, f_analyze = f_A) args(sim1) #> function (reps, n, mean = 0, sd = 1, trim = 0, seed = NA_integer_)  #> NULL res1 <- sim1(4, n = 70, mean = 0.5, sd = 1, trim = 0.2) res1 #>       y_bar #> 1 0.4078913 #> 2 0.5657640 #> 3 0.5072222 #> 4 0.5389756  # bundle data-generation, data-analysis, and performance summary functions sim2 <- bundle_sim(f_generate = f_G, f_analyze = f_A, f_summarize = f_S) args(sim2) #> function (reps, n, mean = 0, sd = 1, trim = 0, calc_sd = FALSE,  #>     seed = NA_integer_, summarize = TRUE)  #> NULL res2 <- sim2(24, n = 7, mean = 0, sd = 1, trim = 0.2, calc_sd = TRUE) res2 #>                M        SD #> y_bar 0.07659681 0.3404206  # bundle data-generation and data-analysis functions, returning results as a list sim3 <- bundle_sim(f_generate = f_G, f_analyze = f_A, stack_reps = FALSE) args(sim3) #> function (reps, n, mean = 0, sd = 1, trim = 0, seed = NA_integer_)  #> NULL res3 <- sim3(4, n = 70, mean = 0.5, sd = 3, trim = 0.2) res3 #> [[1]] #>      y_bar #> 1 1.492354 #>  #> [[2]] #>        y_bar #> 1 0.04252261 #>  #> [[3]] #>       y_bar #> 1 0.7034902 #>  #> [[4]] #>       y_bar #> 1 0.5501354 #>"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_absolute.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate absolute performance criteria and MCSE — calc_absolute","title":"Calculate absolute performance criteria and MCSE — calc_absolute","text":"Calculates absolute bias, variance, mean squared error (mse)   root mean squared error (rmse). function also calculates associated   Monte Carlo standard errors.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_absolute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate absolute performance criteria and MCSE — calc_absolute","text":"","code":"calc_absolute(   data,   estimates,   true_param,   criteria = c(\"bias\", \"variance\", \"stddev\", \"mse\", \"rmse\"),   winz = Inf )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_absolute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate absolute performance criteria and MCSE — calc_absolute","text":"data data frame tibble containing simulation results. estimates vector name column data containing point estimates. true_param vector name column data containing corresponding true parameters. criteria character character vector indicating performance criteria calculated, possible options \"bias\", \"variance\", \"stddev\", \"mse\", \"rmse\". winz numeric value winsorization constant. set finite value, estimates winsorized constant multiple inter-quartile range 25th percentile 75th percentile distribution. instance, setting winz = 3 truncate estimates fall P25 - 3 * IQR P75 + 3 * IQR.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_absolute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate absolute performance criteria and MCSE — calc_absolute","text":"tibble containing number simulation iterations, performance   criteria estimate(s) associated MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_absolute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate absolute performance criteria and MCSE — calc_absolute","text":"","code":"calc_absolute(data = t_res, estimates = est, true_param = true_param) #> # A tibble: 1 × 11 #>   K_absolute    bias bias_mcse    var var_mcse stddev stddev_mcse    mse #>        <int>   <dbl>     <dbl>  <dbl>    <dbl>  <dbl>       <dbl>  <dbl> #> 1       1000 0.00233   0.00638 0.0407  0.00183  0.202     0.00457 0.0407 #> # ℹ 3 more variables: mse_mcse <dbl>, rmse <dbl>, rmse_mcse <dbl>"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_coverage.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate confidence interval coverage, width and MCSE — calc_coverage","title":"Calculate confidence interval coverage, width and MCSE — calc_coverage","text":"Calculates confidence interval coverage width. function also calculates associated Monte Carlo standard errors. confidence interval percentage based calculated lower upper bounds.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_coverage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate confidence interval coverage, width and MCSE — calc_coverage","text":"","code":"calc_coverage(   data,   lower_bound,   upper_bound,   true_param,   criteria = c(\"coverage\", \"width\"),   winz = Inf )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_coverage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate confidence interval coverage, width and MCSE — calc_coverage","text":"data data frame tibble containing simulation results. lower_bound vector name column data containing lower bounds confidence intervals. upper_bound vector name column data containing upper bounds confidence intervals. true_param vector name column data containing corresponding true parameters. criteria character character vector indicating performance criteria calculated, possible options \"coverage\" \"width\". winz numeric value winsorization constant. set finite value, estimates winsorized constant multiple inter-quartile range 25th percentile 75th percentile distribution. instance, setting winz = 3 truncate estimates fall P25 - 3 * IQR P75 + 3 * IQR.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_coverage.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate confidence interval coverage, width and MCSE — calc_coverage","text":"tibble containing number simulation iterations, performance criteria estimate(s) associated MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_coverage.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate confidence interval coverage, width and MCSE — calc_coverage","text":"","code":"calc_coverage(data = t_res, lower_bound = lower_bound,               upper_bound = upper_bound, true_param = true_param) #> # A tibble: 1 × 5 #>   K_coverage coverage coverage_mcse width width_mcse #>        <int>    <dbl>         <dbl> <dbl>      <dbl> #> 1       1000    0.951       0.00683 0.791    0.00179"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_rejection.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate rejection rate and MCSE — calc_rejection","title":"Calculate rejection rate and MCSE — calc_rejection","text":"Calculates rejection rate. function also calculates   associated Monte Carlo standard error.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_rejection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate rejection rate and MCSE — calc_rejection","text":"","code":"calc_rejection(data, p_values, alpha = 0.05, format = \"wide\")"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_rejection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate rejection rate and MCSE — calc_rejection","text":"data data frame tibble containing simulation results. p_values vector name column data containing p-values. alpha scalar vector indicating nominal alpha level(s). Default value set conventional .05. format option \"wide\" (default) produce tibble one row, separate variables specified alpha. Option \"long\" produce tibble one row per specified alpha.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_rejection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate rejection rate and MCSE — calc_rejection","text":"tibble containing number simulation iterations, performance   criteria estimate associated MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_rejection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate rejection rate and MCSE — calc_rejection","text":"","code":"calc_rejection(data = t_res, p_values = p_val) #>   K_rejection rej_rate rej_rate_mcse #> 1        1000    0.702    0.01446361"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate relative performance criteria and MCSE — calc_relative","title":"Calculate relative performance criteria and MCSE — calc_relative","text":"Calculates relative bias, mean squared error (relative mse), root mean squared error (relative rmse). function also calculates associated Monte Carlo standard errors.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate relative performance criteria and MCSE — calc_relative","text":"","code":"calc_relative(   data,   estimates,   true_param,   criteria = c(\"relative bias\", \"relative mse\", \"relative rmse\"),   winz = Inf )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate relative performance criteria and MCSE — calc_relative","text":"data data frame tibble containing simulation results. estimates vector name column data containing point estimates. true_param vector name column data containing corresponding true parameters. criteria character character vector indicating performance criteria calculated, possible options \"relative bias\", \"relative mse\", \"relative rmse\". winz numeric value winsorization constant. set finite value, estimates winsorized constant multiple inter-quartile range 25th percentile 75th percentile distribution. instance, setting winz = 3 truncate estimates fall P25 - 3 * IQR P75 + 3 * IQR.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate relative performance criteria and MCSE — calc_relative","text":"tibble containing number simulation iterations, performance criteria estimate(s) associated MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate relative performance criteria and MCSE — calc_relative","text":"","code":"calc_relative(data = t_res, estimates = est, true_param = true_param) #> # A tibble: 1 × 7 #>   K_relative rel_bias rel_bias_mcse rel_mse rel_mse_mcse rel_rmse rel_rmse_mcse #>        <int>    <dbl>         <dbl>   <dbl>        <dbl>    <dbl>         <dbl> #> 1       1000     1.00        0.0128   0.163      0.00733    0.403        0.0111"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate jack-knife Monte Carlo SE for variance estimators — calc_relative_var","title":"Calculate jack-knife Monte Carlo SE for variance estimators — calc_relative_var","text":"Calculates relative bias, mean squared error (relative mse),   root mean squared error (relative rmse)  variance estimators.   function also calculates associated jack-knife Monte Carlo standard   errors.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate jack-knife Monte Carlo SE for variance estimators — calc_relative_var","text":"","code":"calc_relative_var(   data,   estimates,   var_estimates,   criteria = c(\"relative bias\", \"relative mse\", \"relative rmse\"),   winz = Inf,   var_winz = winz )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate jack-knife Monte Carlo SE for variance estimators — calc_relative_var","text":"data data frame tibble containing simulation results. estimates vector name column data containing point estimates. var_estimates vector name column data containing variance estimates point estimator estimates. criteria character character vector indicating performance criteria calculated, possible options \"relative bias\", \"relative mse\", \"relative rmse\". winz numeric value winsorization constant. set finite value, estimates winsorized constant multiple inter-quartile range 25th percentile 75th percentile distribution. instance, setting winz = 3 truncate estimates fall P25 - 3 * IQR P75 + 3 * IQR. var_winz numeric value winsorization constant variance estimates. set finite value, variance estimates winsorized constant multiple inter-quartile range 25th percentile 75th percentile distribution. instance, setting var_winz = 3 truncate variance estimates fall P25 - 3 * IQR P75 + 3 * IQR. default var_winz set constant winsorize.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate jack-knife Monte Carlo SE for variance estimators — calc_relative_var","text":"tibble containing number simulation iterations, performance   criteria estimate(s) associated MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/calc_relative_var.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate jack-knife Monte Carlo SE for variance estimators — calc_relative_var","text":"","code":"calc_relative_var(data = alpha_res, estimates = A, var_estimates = Var_A) #> # A tibble: 1 × 7 #>   K_relvar rel_bias_var rel_bias_var_mcse rel_mse_var rel_mse_var_mcse #>      <int>        <dbl>             <dbl>       <dbl>            <dbl> #> 1     1000        0.440             0.101       0.726            0.337 #> # ℹ 2 more variables: rel_rmse_var <dbl>, rel_rmse_var_mcse <dbl>"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/create_skeleton.html","id":null,"dir":"Reference","previous_headings":"","what":"Open a simulation skeleton — create_skeleton","title":"Open a simulation skeleton — create_skeleton","text":"Creates opens .R file containing skeleton writing Monte Carlo simulation study.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/create_skeleton.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Open a simulation skeleton — create_skeleton","text":"","code":"create_skeleton()"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/create_skeleton.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Open a simulation skeleton — create_skeleton","text":"","code":"if (FALSE) { # \\dontrun{ create_skeleton() } # }"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/evaluate_by_row.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate a simulation function on each row of a data frame or tibble — evaluate_by_row","title":"Evaluate a simulation function on each row of a data frame or tibble — evaluate_by_row","text":"Evaluates simulation function row data frame   tibble containing parameter values. Returns single tibble parameters   simulation results. function uses furrr::future_pmap,   allows easy parallelization.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/evaluate_by_row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate a simulation function on each row of a data frame or tibble — evaluate_by_row","text":"","code":"evaluate_by_row(   params,   sim_function,   ...,   results_name = \".results\",   .progress = FALSE,   .options = furrr::furrr_options(),   system_time = TRUE,   verbose = TRUE )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/evaluate_by_row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate a simulation function on each row of a data frame or tibble — evaluate_by_row","text":"params data frame tibble containing simulation parameter values. row represent separate set parameter values. Column names must exactly match argument names sim_function. Non-matching columns ignored. sim_function function evaluated, argument names matching variable names params. function must return data.frame, tibble, vector. ... additional arguments passed sim_function. results_name character string set name column storing results simulation. Default \".results\". .progress single logical. progress bar displayed? works multisession, multicore, multiprocess futures. Note multicore/multisession future falls back sequential, progress bar displayed. Warning: .progress argument deprecated removed future version furrr favor using robust progressr package. .options future specific options use workers. must result call furrr_options(). system_time logical indicating whether print computation time. TRUE default. verbose logical indicating whether display message variables used function evaluation. TRUE default.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/evaluate_by_row.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate a simulation function on each row of a data frame or tibble — evaluate_by_row","text":"tibble containing parameter values simulation results.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/evaluate_by_row.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate a simulation function on each row of a data frame or tibble — evaluate_by_row","text":"","code":"df <- data.frame(   n = 3:5,   lambda = seq(8, 16, 4) )  evaluate_by_row(df, rpois) #> Evaluating rpois() using the following variables: n, lambda #> Warning: UNRELIABLE VALUE: Future (<unnamed-1>) unexpectedly generated random numbers without specifying argument 'seed'. There is a risk that those random numbers are not statistically sound and the overall results might be invalid. To fix this, specify 'seed=TRUE'. This ensures that proper, parallel-safe random numbers are produced. To disable this check, use 'seed=NULL', or set option 'future.rng.onMisuse' to \"ignore\". #>    user  system elapsed  #>   0.066   0.009   0.074  #> # A tibble: 12 × 3 #>        n lambda .results #>    <int>  <dbl>    <int> #>  1     3      8        7 #>  2     3      8        3 #>  3     3      8        3 #>  4     4     12        7 #>  5     4     12       15 #>  6     4     12       12 #>  7     4     12        9 #>  8     5     16       16 #>  9     5     16       14 #> 10     5     16       15 #> 11     5     16       14 #> 12     5     16       18"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/extrapolate_coverage.html","id":null,"dir":"Reference","previous_headings":"","what":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_coverage","title":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_coverage","text":"Given set bootstrap confidence intervals calculated across   sub-samples different numbers replications, extrapolates confidence   interval coverage width bootstrap confidence intervals   specified (larger) number bootstraps. function also calculates   associated Monte Carlo standard errors. confidence interval percentage   based calculated lower upper bounds.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/extrapolate_coverage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_coverage","text":"","code":"extrapolate_coverage(   data,   CI_subsamples,   true_param,   B_target = Inf,   criteria = c(\"coverage\", \"width\"),   winz = Inf,   nested = FALSE,   format = \"wide\",   width_trim = 0,   cover_na_val = NA,   width_na_val = NA )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/extrapolate_coverage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_coverage","text":"data data frame tibble containing simulation results. CI_subsamples list name column data containing list confidence intervals calculated based sub-samples different numbers replications. true_param vector name column data containing corresponding true parameters. B_target number bootstrap replications criteria extrapolated, default B = Inf. criteria character character vector indicating performance criteria calculated, possible options \"coverage\" \"width\". winz numeric value winsorization constant. set finite value, estimates winsorized constant multiple inter-quartile range 25th percentile 75th percentile distribution. instance, setting winz = 3 truncate estimates fall P25 - 3 * IQR P75 + 3 * IQR. nested logical value controlling format output. FALSE (default), results returned data frame rows distinct number bootstraps. TRUE, results returned data frame single row, performance criterion containing nested data frame. format character string controlling format output CI_subsamples results one type confidence interval. \"wide\" (default), performance criterion separate column CI type. \"long\", performance criterion single variable, separate rows CI type. width_trim numeric value specifying trimming percentage use summarizing CI widths across replications single set bootstraps, default 0.0 (.e., use regular arithmetic mean). cover_na_val numeric value use calculating coverage bootstrap CI end-points missing. Default NA. width_na_val numeric value use calculating width bootstrap CI end-points missing. Default NA.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/extrapolate_coverage.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_coverage","text":"tibble containing number simulation iterations, performance   criteria estimate(s) associated MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/extrapolate_coverage.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_coverage","text":"Boos DD, Zhang J (2000). “Monte Carlo evaluation resampling-based hypothesis tests.” Journal American Statistical Association, 95(450), 486–492. doi:10.1080/01621459.2000.10474226 .","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/extrapolate_coverage.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_coverage","text":"","code":"dgp <- function(N, mu, nu) {   mu + rt(N, df = nu) }  estimator <- function(    dat,     B_vals = c(49,59,89,99),     m = 4,     trim = 0.1 ) {     # compute estimate and standard error   N <- length(dat)   est <- mean(dat, trim = trim)   se <- sd(dat) / sqrt(N)    # compute booties   booties <- replicate(max(B_vals), {     x <- sample(dat, size = N, replace = TRUE)     data.frame(       M = mean(x, trim = trim),       SE = sd(x) / sqrt(N)     )   }, simplify = FALSE) |>     dplyr::bind_rows()    # confidence intervals for each B_vals   CIs <- bootstrap_CIs(     boot_est = booties$M,     boot_se = booties$SE,     est = est,     se = se,     CI_type = c(\"normal\",\"basic\",\"student\",\"percentile\"),     B_vals = B_vals,     reps = m,     format = \"wide-list\"   )    res <- data.frame(     est = est,     se = se   )   res$CIs <- CIs    res }  #' build a simulation driver function simulate_bootCIs <- bundle_sim(   f_generate = dgp,   f_analyze = estimator )  boot_results <- simulate_bootCIs(   reps = 50, N = 20, mu = 2, nu = 3,   B_vals = seq(49, 199, 50), )  extrapolate_coverage(   data = boot_results,   CI_subsamples = CIs,   true_param = 2 ) #>     K_boot_coverage bootstraps boot_coverage_normal boot_coverage_basic #> 49               50         49            0.9400000           0.9000000 #> 99               50         99            0.9650000           0.9500000 #> 149              50        149            0.9650000           0.9450000 #> 199              50        199            0.9600000           0.9600000 #> Inf              50        Inf            0.9736769           0.9778768 #>     boot_coverage_student boot_coverage_percentile boot_coverage_mcse_normal #> 49               0.920000                0.8850000                0.03159049 #> 99               0.970000                0.9350000                0.02259899 #> 149              0.975000                0.9400000                0.02475389 #> 199              0.980000                0.9600000                0.02799417 #> Inf              1.003227                0.9781261                0.02545305 #>     boot_coverage_mcse_basic boot_coverage_mcse_student #> 49                0.03779645                 0.02896162 #> 99                0.02945075                 0.02099563 #> 149               0.02970089                 0.02051630 #> 199               0.02799417                 0.02000000 #> Inf               0.02971749                 0.02223154 #>     boot_coverage_mcse_percentile boot_width_normal boot_width_basic #> 49                     0.03725943          1.165784         1.104340 #> 99                     0.02928571          1.172612         1.178470 #> 149                    0.03077237          1.171643         1.184977 #> 199                    0.02799417          1.171215         1.199969 #> Inf                    0.03187910          1.174443         1.231652 #>     boot_width_student boot_width_percentile boot_width_mcse_normal #> 49            1.200169              1.104340             0.04385943 #> 99            1.279780              1.178470             0.04204718 #> 149           1.298303              1.184977             0.04173253 #> 199           1.311018              1.199969             0.04149441 #> Inf           1.348443              1.231652             0.04139176 #>     boot_width_mcse_basic boot_width_mcse_student boot_width_mcse_percentile #> 49             0.04243187              0.05495744                 0.04243187 #> 99             0.04488293              0.05261230                 0.04488293 #> 149            0.04369724              0.05253379                 0.04369724 #> 199            0.04512994              0.05213456                 0.04512994 #> Inf            0.04690010              0.05236747                 0.04690010  extrapolate_coverage(   data = boot_results,   CI_subsamples = CIs,   true_param = 2,   B_target = 999,   format = \"long\" ) #>    K_boot_coverage bootstraps    CI_type boot_coverage boot_coverage_mcse #> 1               50         49     normal     0.9400000         0.03159049 #> 2               50         99     normal     0.9650000         0.02259899 #> 3               50        149     normal     0.9650000         0.02475389 #> 4               50        199     normal     0.9600000         0.02799417 #> 5               50        999     normal     0.9721437         0.02527111 #> 6               50         49      basic     0.9000000         0.03779645 #> 7               50         99      basic     0.9500000         0.02945075 #> 8               50        149      basic     0.9450000         0.02970089 #> 9               50        199      basic     0.9600000         0.02799417 #> 10              50        999      basic     0.9741684         0.02927008 #> 11              50         49    student     0.9200000         0.02896162 #> 12              50         99    student     0.9700000         0.02099563 #> 13              50        149    student     0.9750000         0.02051630 #> 14              50        199    student     0.9800000         0.02000000 #> 15              50        999    student     0.9992488         0.02164101 #> 16              50         49 percentile     0.8850000         0.03725943 #> 17              50         99 percentile     0.9350000         0.02928571 #> 18              50        149 percentile     0.9400000         0.03077237 #> 19              50        199 percentile     0.9600000         0.02799417 #> 20              50        999 percentile     0.9735647         0.03097510 #>    boot_width boot_width_mcse #> 1    1.165784      0.04385943 #> 2    1.172612      0.04204718 #> 3    1.171643      0.04173253 #> 4    1.171215      0.04149441 #> 5    1.174051      0.04139549 #> 6    1.104340      0.04243187 #> 7    1.178470      0.04488293 #> 8    1.184977      0.04369724 #> 9    1.199969      0.04512994 #> 10   1.225518      0.04649338 #> 11   1.200169      0.05495744 #> 12   1.279780      0.05261230 #> 13   1.298303      0.05253379 #> 14   1.311018      0.05213456 #> 15   1.341228      0.05228401 #> 16   1.104340      0.04243187 #> 17   1.178470      0.04488293 #> 18   1.184977      0.04369724 #> 19   1.199969      0.04512994 #> 20   1.225518      0.04649338"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/extrapolate_rejection.html","id":null,"dir":"Reference","previous_headings":"","what":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_rejection","title":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_rejection","text":"Given set bootstrap confidence intervals calculated across   sub-samples different numbers replications, extrapolates confidence   interval coverage width bootstrap confidence intervals   specified (larger) number bootstraps. function also calculates   associated Monte Carlo standard errors. confidence interval percentage   based calculated lower upper bounds.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/extrapolate_rejection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_rejection","text":"","code":"extrapolate_rejection(   data,   pvalue_subsamples,   B_target = Inf,   alpha = 0.05,   nested = FALSE,   format = \"wide\" )"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/extrapolate_rejection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_rejection","text":"data data frame tibble containing simulation results. pvalue_subsamples list name column data containing list confidence intervals calculated based sub-samples different numbers replications. B_target number bootstrap replications criteria extrapolated, default B = Inf. alpha scalar vector indicating nominal alpha level(s). Default value set conventional .05. nested logical value controlling format output. FALSE (default), results returned data frame rows distinct number bootstraps. TRUE, results returned data frame single row, performance criterion containing nested data frame. format character string controlling format output CI_subsamples results one type confidence interval. \"wide\" (default), performance criterion separate column CI type. \"long\", performance criterion single variable, separate rows CI type.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/extrapolate_rejection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_rejection","text":"tibble containing number simulation iterations, performance   criteria estimate(s) associated MCSE.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/extrapolate_rejection.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_rejection","text":"Boos DD, Zhang J (2000). “Monte Carlo evaluation resampling-based hypothesis tests.” Journal American Statistical Association, 95(450), 486–492. doi:10.1080/01621459.2000.10474226 .","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/extrapolate_rejection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extrapolate coverage and width using sub-sampled bootstrap confidence intervals. — extrapolate_rejection","text":"","code":"# function to generate data from two distinct populations dgp <- function(N_A, N_B, shape_A, scale_A, shape_B, scale_B) {   data.frame(     group = rep(c(\"A\",\"B\"), c(N_A, N_B)),       y = c(         rgamma(N_A, shape = shape_A, scale = scale_A),         rgamma(N_B, shape = shape_B, scale = scale_B)       )   ) }  # function to do a bootstrap t-test estimator <- function(     dat,     B_vals = c(49,59,89,99), # number of booties to evaluate     pval_reps = 4L ) {   stat <- t.test(y ~ group, data = dat)$statistic    # create bootstrap replications under the null of no difference   boot_dat <- dat   booties <- replicate(max(B_vals), {     boot_dat$group <- sample(dat$group)     t.test(y ~ group, data = boot_dat)$statistic   })    # calculate multiple bootstrap p-values using sub-sampling of replicates   res <- data.frame(stat = stat)    res$pvalue_subsamples <- bootstrap_pvals(     boot_stat = booties,     stat = stat,     B_vals = B_vals,     reps = pval_reps,     enlist = TRUE   )    res }  # create simulation driver simulate_boot_pvals <- bundle_sim(   f_generate = dgp,   f_analyze = estimator )  # replicate the bootstrap process x <- simulate_boot_pvals(   reps = 50L,   N_A = 20, N_B = 25,   shape_A = 7, scale_A = 2,   shape_B = 4, scale_B = 3,   B_vals = c(49, 99, 149, 199),   pval_reps = 2L )  extrapolate_rejection(   data = x,   pvalue_subsamples = pvalue_subsamples,   B_target = 1999,   alpha = c(.01, .05, .10) ) #>   K_boot_rejection bootstraps boot_rej_rate_alpha_01 boot_rej_rate_alpha_05 #> 1               50         49             0.11000000              0.2800000 #> 2               50         99             0.03000000              0.2500000 #> 3               50        149             0.07000000              0.2900000 #> 4               50        199             0.04000000              0.3000000 #> 5               50       1999             0.02170504              0.2895512 #>   boot_rej_rate_alpha_10 boot_rej_rate_mcse_alpha_01 #> 1              0.3900000                  0.04113194 #> 2              0.4300000                  0.02217739 #> 3              0.4200000                  0.03502186 #> 4              0.4000000                  0.02799417 #> 5              0.4233506                  0.02951073 #>   boot_rej_rate_mcse_alpha_05 boot_rej_rate_mcse_alpha_10 #> 1                  0.05917804                  0.06591584 #> 2                  0.05758756                  0.07000000 #> 3                  0.06076049                  0.07050836 #> 4                  0.06546537                  0.06998542 #> 5                  0.06766279                  0.07363925  extrapolate_rejection(   data = x,   pvalue_subsamples = pvalue_subsamples,   B_target = Inf,   alpha = c(.01, .05, .10),   nested = TRUE ) #>   K_boot_rejection            bootstraps #> 1               50 49, 99, 149, 199, Inf #>                                                                                                                                                                        boot_rej_rate #> 1 0.11000000, 0.03000000, 0.07000000, 0.04000000, 0.01967668, 0.28000000, 0.25000000, 0.29000000, 0.30000000, 0.29002613, 0.39000000, 0.43000000, 0.42000000, 0.40000000, 0.42401445 #>                                                                                                                                                                   boot_rej_rate_mcse #> 1 0.04113194, 0.02217739, 0.03502186, 0.02799417, 0.02991865, 0.05917804, 0.05758756, 0.06076049, 0.06546537, 0.06842138, 0.06591584, 0.07000000, 0.07050836, 0.06998542, 0.07402652"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/repeat_and_stack.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeat an expression multiple times and (optionally) stack the results. — repeat_and_stack","title":"Repeat an expression multiple times and (optionally) stack the results. — repeat_and_stack","text":"Repeat expression (usually involving random number   generation) multiple times. Optionally, organize results   data.frame stacks output replications   expression.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/repeat_and_stack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeat an expression multiple times and (optionally) stack the results. — repeat_and_stack","text":"","code":"repeat_and_stack(n, expr, id = NULL, stack = TRUE)"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/repeat_and_stack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Repeat an expression multiple times and (optionally) stack the results. — repeat_and_stack","text":"n Number times repeat expression expr expression evaluated. id Character string use creating variable unique identifier repetition. set NULL (default), identifier created. stack Logical value indicating whether organize results data.frame.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/repeat_and_stack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Repeat an expression multiple times and (optionally) stack the results. — repeat_and_stack","text":"stack = TRUE (default), results evaluation   expr stacked together using rbind unique identifier stored variable id (specified). stack   = FALSE, list length n entries corresponding   output replication expr, names corresponding unique identifier (specified)","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/repeat_and_stack.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Repeat an expression multiple times and (optionally) stack the results. — repeat_and_stack","text":"","code":"repeat_and_stack(n = 3, data.frame(x = rexp(2))) #>           x #> 1 0.6993889 #> 2 0.1802598 #> 3 0.4364060 #> 4 2.9640214 #> 5 2.6859047 #> 6 0.5160765 repeat_and_stack(n = 3, data.frame(x = rexp(2)), id = \"ID\") #>   ID          x #> 1  1 0.43494982 #> 2  1 1.25056845 #> 3  2 0.04620374 #> 4  2 0.34424903 #> 5  3 1.23769849 #> 6  3 1.40667213  repeat_and_stack(n = 3, data.frame(x = rexp(2)), stack = FALSE) #> [[1]] #>          x #> 1 1.829160 #> 2 1.101649 #>  #> [[2]] #>          x #> 1 0.234430 #> 2 1.332338 #>  #> [[3]] #>           x #> 1 0.4213795 #> 2 1.2648624 #>  repeat_and_stack(n = 3, data.frame(x = rexp(2)), id = \"ID\", stack = FALSE) #> $`1` #>           x #> 1 0.2104247 #> 2 0.4283194 #>  #> $`2` #>            x #> 1 1.39053525 #> 2 0.08336016 #>  #> $`3` #>           x #> 1 0.1163788 #> 2 1.3802114 #>"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/t_res.html","id":null,"dir":"Reference","previous_headings":"","what":"t-test simulation results — t_res","title":"t-test simulation results — t_res","text":"dataset containing simulation results study just runs t-test.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/t_res.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"t-test simulation results — t_res","text":"","code":"t_res"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/t_res.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"t-test simulation results — t_res","text":"tibble 1,000 rows 5 variables: est estimate mean difference. p_val p-value t-test. lower_bound lower bound confidence interval. upper_bound upper bound confidence interval. true_param true mean difference used generate data.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/welch_res.html","id":null,"dir":"Reference","previous_headings":"","what":"Welch t-test simulation results — welch_res","title":"Welch t-test simulation results — welch_res","text":"dataset containing simulation results study comparing Welch t-test conventional t-test.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/welch_res.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Welch t-test simulation results — welch_res","text":"","code":"welch_res"},{"path":"https://meghapsimatrix.github.io/simhelpers/reference/welch_res.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Welch t-test simulation results — welch_res","text":"tibble 16,000 rows 11 variables: n1 sample size Group 1. n2 sample size Group 2. mean_diff true difference means two groups used generate data. iterations number iterations. seed seed used generate data. method indicates whether Welch conventional t-test used. est estimate mean difference. var variance estimate. p_val p-value t-test. lower_bound lower bound confidence interval. upper_bound upper bound confidence interval.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/news/index.html","id":"simhelpers-0319999","dir":"Changelog","previous_headings":"","what":"simhelpers 0.3.1.9999","title":"simhelpers 0.3.1.9999","text":"Added option specify unique ID variable every repetition repeat_and_stack() bundle_sim(). Refactored bundle_sim() uses repeat_and_stack() internally. Refactored evaluate_by_row() uses variables match argument names function evaluated.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/news/index.html","id":"simhelpers-031","dir":"Changelog","previous_headings":"","what":"simhelpers 0.3.1","title":"simhelpers 0.3.1","text":"CRAN release: 2025-01-10 Added support bias-corrected bias-corrected--accelerated (BCa) bootstrap confidence intervals. Corrected error documentation bundle_sim().","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/news/index.html","id":"simhelpers-030","dir":"Changelog","previous_headings":"","what":"simhelpers 0.3.0","title":"simhelpers 0.3.0","text":"CRAN release: 2024-09-04 Added functions calculating bootstrap p-values confidence intervals estimating rejection rates, coverage rates, interval widths extrapolating across bootstrap subsamples. Added repeat_and_stack() function, similar base R replicate() now deprecated purrr::rerun(), option stack output single data.frame. Added \"stddev\" performance criterion calc_absolute(). Added winsorize options calc_absolute(), calc_relative(), calc_relative_var(), calc_coverage().","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/news/index.html","id":"simhelpers-021","dir":"Changelog","previous_headings":"","what":"simhelpers 0.2.1","title":"simhelpers 0.2.1","text":"CRAN release: 2024-02-29 Fixed issues unit tests Mac OS, M1Mac, NoLD.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/news/index.html","id":"simhelpers-020","dir":"Changelog","previous_headings":"","what":"simhelpers 0.2.0","title":"simhelpers 0.2.0","text":"CRAN release: 2024-02-23 Added new, experimental function bundle_sim() compose set functions simulation driver. Added argument evaluate_by_row() control name variable simulation results stored. Revised calc_*() functions can take vectors variable names specified dataset. calc_rejection() can now compute rejection rates multiple alpha levels. Renamed K variable computed calc_*() functions avoid -writing variables using multiple performance calculations inside dplyr::summarize(). Updated syntax vignettes examples use current tidyverse conventions.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/news/index.html","id":"simhelpers-012","dir":"Changelog","previous_headings":"","what":"simhelpers 0.1.2","title":"simhelpers 0.1.2","text":"CRAN release: 2022-05-03 Removed import defunct function furrr package.","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/news/index.html","id":"simhelpers-011","dir":"Changelog","previous_headings":"","what":"simhelpers 0.1.1","title":"simhelpers 0.1.1","text":"CRAN release: 2021-02-14 Fixed formula jacknife MCSE","code":""},{"path":"https://meghapsimatrix.github.io/simhelpers/news/index.html","id":"simhelpers-010","dir":"Changelog","previous_headings":"","what":"simhelpers 0.1.0","title":"simhelpers 0.1.0","text":"CRAN release: 2020-03-31 First version","code":""}]
