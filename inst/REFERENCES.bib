@article{tipton_small-sample_2015,
	title = {Small-{Sample} {Adjustments} for {Tests} of {Moderators} and {Model} {Fit} {Using} {Robust} {Variance} {Estimation} in {Meta}-{Regression}},
	volume = {40},
	issn = {1076-9986, 1935-1054},
	url = {https://journals.sagepub.com/doi/10.3102/1076998615606099},
	doi = {10.3102/1076998615606099},
	language = {en},
	number = {6},
	urldate = {2020-01-27},
	journal = {Journal of Educational and Behavioral Statistics},
	author = {Tipton, Elizabeth and Pustejovsky, James E.},
	month = dec,
	year = {2015},
	pages = {604--634},
	file = {Tipton & Pustejovsky (2015) - RVE Meta.pdf:/Users/meghajoshi/Box Sync/Dissertation_Joshi/articles/methods_studies/Tipton & Pustejovsky (2015) - RVE Meta.pdf:application/pdf}
}

@article{boos2000MonteCarloEvaluation,
  title = {{{Monte Carlo}} evaluation of resampling-based hypothesis tests},
  author = {Boos, Dennis D. and Zhang, Ji},
  year = {2000},
  month = jun,
  journal = {Journal of the American Statistical Association},
  volume = {95},
  number = {450},
  pages = {486--492},
  doi = {10.1080/01621459.2000.10474226}
}

@article{davidson2000BootstrapTestsHow,
  title = {Bootstrap Tests: How Many Bootstraps?},
  shorttitle = {Bootstrap Tests},
  author = {Davidson, Russell and MacKinnon, James G.},
  year = {2000},
  month = jan,
  journal = {Econometric Reviews},
  volume = {19},
  number = {1},
  pages = {55--68},
  issn = {0747-4938, 1532-4168},
  doi = {10.1080/07474930008800459},
  urldate = {2024-06-30},
  langid = {english},
  file = {C:\Users\jamespustejovsky\Zotero\storage\WIS989IY\Davidson and MacKinnon - 2000 - Bootstrap tests how many bootstraps.pdf}
}

@article{joshiClusterWildBootstrapping2022,
  title = {Cluster Wild Bootstrapping to Handle Dependent Effect Sizes in Meta-Analysis with a Small Number of Studies},
  author = {Joshi, Megha and Pustejovsky, James E. and Beretvas, S. Natasha},
  year = {2022},
  journal = {Research Synthesis Methods},
  volume = {13},
  number = {4},
  pages = {457--477},
  issn = {1759-2887},
  doi = {10.1002/jrsm.1554},
  urldate = {2023-07-17},
  abstract = {The most common and well-known meta-regression models work under the assumption that there is only one effect size estimate per study and that the estimates are independent. However, meta-analytic reviews of social science research often include multiple effect size estimates per primary study, leading to dependence in the estimates. Some meta-analyses also include multiple studies conducted by the same lab or investigator, creating another potential source of dependence. An increasingly popular method to handle dependence is robust variance estimation (RVE), but this method can result in inflated Type I error rates when the number of studies is small. Small-sample correction methods for RVE have been shown to control Type I error rates adequately but may be overly conservative, especially for tests of multiple-contrast hypotheses. We evaluated an alternative method for handling dependence, cluster wild bootstrapping, which has been examined in the econometrics literature but not in the context of meta-analysis. Results from two simulation studies indicate that cluster wild bootstrapping maintains adequate Type I error rates and provides more power than extant small-sample correction methods, particularly for multiple-contrast hypothesis tests. We recommend using cluster wild bootstrapping to conduct hypothesis tests for meta-analyses with a small number of studies. We have also created an R package that implements such tests.},
  copyright = {{\copyright} 2022 John Wiley \& Sons, Ltd},
  langid = {english},
  keywords = {cluster wild bootstrap,dependence,meta-analysis,robust variance estimation},
  file = {C\:\\Users\\jamespustejovsky\\Zotero\\storage\\5MJZLJUY\\Joshi et al. - 2022 - Cluster wild bootstrapping to handle dependent eff.pdf;C\:\\Users\\jamespustejovsky\\Zotero\\storage\\8TKYMNAD\\jrsm.html}
}
